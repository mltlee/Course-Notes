\section{Riemann's Zeta Function and the Prime Number Theorem}\label{sec:3}

\subsection{The Riemann Zeta Function}\label{subsec:3.1}
In order to prove the Prime Number Theorem, we need to 
first introduce the Riemann zeta function. 

\begin{defn}\label{def:3.1}
For $s \in \C$ with $\Re(s) > 1$, we define the 
{\bf Riemann zeta function} by 
\[ \zeta(s) := \sum_{n=1}^\infty \frac1{n^s}. \]
We will denote $s = \sigma + it$ where $\sigma, t \in \R$. 
\end{defn}

Note that the series $\sum_{n=1}^\infty n^{-s}$ converges 
absolutely when $\Re(s) > 1$. 

Recall that the infinite product $\prod_n (1 + a_n)$ 
converges absolutely (that is, it is finite and non-zero)
if and only if $\sum_n |a_n|$ converges. We have the 
{\bf Euler product representation} of $\zeta(s)$ given 
in the following lemma. 

\begin{lemma}[Euler product]\label{lemma:3.2}
For $s \in \C$ with $\Re(s) > 1$, we have 
\[ \prod_p \left( 1 - \frac1{p^s} \right)^{\!-1} = 
\sum_{n=1}^\infty \frac1{n^s}. \]
\end{lemma}
\begin{pf}
Note that 
\[ \prod_p \left( 1 - \frac1{p^s} \right)^{\!-1} = 
\prod_p \left(1 + \frac1{p^2} + \frac1{p^3} + \cdots \right). \]
A typical term in the sum is of the form 
\[ \frac{1}{p_1^{\alpha_1s} \cdots p_k^{\alpha_ks}}
= \frac{1}{(p_1^{\alpha_1} \cdots p_k^{\alpha_k})^s}. \]
By the Fundamental Theorem of Arithmetic, every positive 
integer can be expressed uniquely as a product of primes, 
so the identity holds.
\end{pf}

\begin{thm}\label{thm:3.3}
$\zeta(s)$ can be analytically continued to $s \in \C$ with 
$\Re(s) > 0$ and $s \neq 1$. It is analytic except 
at the point $s = 1$ where it has a simple pole with residue
$1$. 
\end{thm}
\begin{pf}
For $s \in \C$ with $\Re(s) > 1$, we have 
$\zeta(s) = \sum_{n=1}^\infty n^{-s}$. By Abel's 
summation formula with $a_n = 1$ and $f(x) = x^{-s}$, 
we find that 
\[ \sum_{n\leq x} \frac{1}{n^s} = \frac{\floor x}{x^s}
+ s\int_1^x \frac{\floor u}{u^{s+1}}\dd u. \]
Letting $x \to \infty$, we obtain 
\begin{align*}
    \zeta(s) &= 0 + s\int_1^\infty \frac{\floor u}{u^{s+1}}\dd u \\
    &= s \int_1^\infty \frac{u - (u - \floor u)}{u^{s+1}}\dd u \\
    &= s \int_1^\infty \frac{u}{u^{s+1}}\dd u - 
    s \int_1^\infty \frac{u - \floor u}{u^{s+1}}\dd u \\
    &= s \left( \frac{u^{1-s}}{1-s} \biggr\rvert_1^\infty 
    \right)
    - s \int_1^\infty \frac{u - \floor u}{u^{s+1}}\dd u \\
    &= \frac{s}{s-1} - s \int_1^\infty \frac{u - \floor u}{u^{s+1}}\dd u
\end{align*}
for $\Re(s) > 1$. Note that 
\[ \int_1^\infty \frac{u - \floor u}{u^{s+1}}\dd u \]
converges for $\Re(s) > 0$ and represents an analytic function. Therefore, we see that 
\[ \frac{s}{s-1} - s \int_1^\infty \frac{u - \floor u}{u^{s+1}}\dd u \] 
is an analytic function for $\Re(s) > 0$ with $s \neq 1$. 
This gives a meromorphic continuation of $\zeta(s)$ 
to the region $\{s \in \C : \Re(s) > 0\}$. Finally, note that 
$\frac{s}{s-1}$ has a simple pole with residue $1$ at $s = 1$.
\end{pf}

\begin{thm}\label{thm:3.4}
$\zeta(s)$ has no zeroes in the region $\{s \in \C : 
\Re(s) \geq 1\}$. 
\end{thm}
\begin{pf}
If $\Re(s) > 1$, then $\prod_p (1 - \frac1{p^s})^{-1}$ 
converges, so $\zeta(s) \neq 0$. 

It only remains to consider the case where $\Re(s) = 1$. 
We will first do some preliminary work. 

Recall that we denote $s = \sigma + it$ where $\sigma, t \in \R$. Let $\sigma > 1$. Then for all $ t \in \R$, we have 
\[ \log^*(\zeta(\sigma + it)) = 
\log \left( \prod_p \left(1 + \frac1{p^s}\right)^{\!-1}\right) = \sum_p \sum_{n=1}^\infty \frac1n \left( \frac1{p^{ns}} \right), \]
where $\log$ denotes the principal branch and 
$\log^*$ denotes some branch of the logarithm (we have to be
careful here as we are considering complex numbers). Comparing
the real parts of the above equality, we have 
\[ \log|\zeta(\sigma+it)| = \sum_p \sum_{n=1}^\infty 
\frac{p^{-\sigma n} \cos(nt \log p)}{n}, \]
since we can write 
\[ p^{-int} = e^{-int \log p} = \cos(-nt \log p) + 
i \sin(-nt \log p) = \cos(nt \log p) - i\sin(nt \log p) \]
and therefore $\Re(p^{-int}) = \cos(nt \log p)$. 
Moreover, observe that we have the inequality 
\begin{align*}
    0 \leq 2(1+\cos\theta)^2 
    &= 2(1 + 2\cos\theta + \cos^2\theta) \\
    &= 2 + 4\cos\theta + 2\cos^2\theta \\
    &= 3 + 4\cos\theta + (2\cos^2\theta - 1) \\
    &= 3 + 4\cos\theta + \cos(2\theta). 
\end{align*}
From this, we can deduce that 
\[ \sum_p \sum_{n=1}^\infty \frac{p^{-\sigma n}}n 
(3 + 4\cos(nt \log p) + \cos(2nt \log p)) \geq 0. \]
Therefore, we have 
\[ \log|\zeta(\sigma)|^3 + \log|\zeta(\sigma+it)|^4 + 
\log|\zeta(\sigma+2it)| \geq 0. \]
In particular, we see that 
\begin{equation}
    |\zeta(\sigma)|^3 \cdot |\zeta(\sigma + it)|^4 
    \cdot |\zeta(\sigma+2it)| \geq 1 \label{eq:3.1}
\end{equation} 
for $\sigma > 1$ and $t \in \R$. 

Suppose now that $1 + it_0$ is a zero of $\zeta(s)$, 
and note that $t_0 \neq 0$ as $\zeta(s)$ has a pole at 
$s = 1$. By taking $t \to 1^+$ (that is, from the right), 
we observe tht 
\[ |\zeta(s)| = O((\sigma - 1)^{-1}) \]
since $1$ is a simple pole of $\zeta(s)$. Moreover, 
since $1 + it_0$ is a zero of $\zeta(s)$, we have 
$|\zeta(\sigma + it_0)| = O(\sigma-1)$ as 
$\sigma \to 1^+$. Finally, we have 
$|\zeta(\sigma + 2it_0)| = O(1)$ as $\sigma \to 1^+$ 
since $1 + 2it_0$ is not a simple pole of $\zeta(s)$. 
It follows that 
\[ |\zeta(\sigma)|^3 \cdot |\zeta(\sigma + it)|^4 
\cdot |\zeta(\sigma + 2it)| = 
O((\sigma - 1)^{-3}) \cdot O((\sigma - 1)^4) \cdot O(1) 
= O(\sigma - 1). \]
Thus, $|\zeta(s)|^3 \cdot |\zeta(\sigma+it)|^4 \cdot 
|\zeta(\sigma + 2it)|$ tends to $0$ as $\sigma \to 1^+$. 
But this contradicts that the lower bound we found in (\eqref{eq:3.1}), 
so we conclude that $\zeta(s)$ cannot have a zero when 
$\Re(s) = 1$. 
\end{pf}

\subsection{Newman's Theorem}\label{subsec:3.2}

\begin{thm}[Newman]\label{thm:3.5}
Let $\{a_n\}_{n=1}^\infty$ be a sequence of complex numbers with $|a_n| \leq 1$ for all $n \geq 1$. 
Consider the series $\sum_{n=1}^\infty a_n/n^s$, which converges to an analytic function 
$F(s)$ for $\Re(s) > 1$. If $F(s)$ can be analytically continued to $\Re(s) \geq 1$, then 
$\sum_{n=1}^\infty a_n/n^s$ converges to $F(s)$ for $\Re(s) \geq 1$. 
\end{thm}
\begin{pf}
Let $w \in \C$ with $\Re(w) \geq 1$. Then $F(z+w)$ is analytic for $\Re(z) \geq 0$. Choose 
$R \geq 1$ and let $\delta = \delta(R) > 0$ so that $F(z+w)$ is analytic on the region 
\[ \tilde\Gamma := \{z \in \C : \Re(z) \geq -\delta \text{ and } |z| \leq R\}. \]
To see why such a $\delta > 0$ exists, first note that $F(z+w)$ is analytic for $\Re(z) \geq 0$. 
Consider the line $L = \{z = iy : |y| \leq R\}$. Every point in $L$ has an open cover such that 
$F(z+w)$ is analytic on that cover; call the union of these covers $U$. Since $L$ is compact\footnote{Recall that a set $X$ is compact if every open cover of $X$ has a finite subcover.}, there exists a finite open subcover $\tilde U$ of $U$ such that 
$L \subseteq \tilde U \subseteq U$. Since the number of open sets in $\tilde U$ is finite, 
it follows that such a $\delta > 0$ exists.

Let $M$ denote the maximum of $|F(z+w)|$ on $\tilde \Gamma$, and let $\Gamma$ denote the contour 
obtained by following the outside of $\tilde\Gamma$ in a counterclockwise path. Let $A$ be the 
part of $\Gamma$ in $\Re(z) > 0$, and let $B = \Gamma \setminus A$. For $N \in \N$, consider the 
function 
\[ F(z+w)N^z \left( \frac1z + \frac z{R^2} \right), \]
which is analytic on $\tilde\Gamma$ except at $z = 0$ where there is a simple pole with residue 
$F(0+w) N^0 = F(w)$. By Cauchy's residue theorem, we obtain 
\begin{align*}
    2\pi i F(w) &= \int_\Gamma F(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z \\
    &= \int_A F(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z + 
    \int_B F(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z. \tag{3.2}\label{eq:3.2} 
\end{align*}
Observe that $F(z+w)$ is equal to its series on $A$. We split the series as 
\[ S_N(z+w) = \sum_{n=1}^N \frac{a_n}{n^{z+w}} \]
and $R_N(z+w) = F(z+w) - S_N(z+w)$. Note that $S_N(z+w)$ is analytic for all $z \in \C$. Let 
$C$ be the contour given by the path $|z| = R$ taken in the counterclockwise direction. 
By Cauchy's residue theorem, we obtain 
\[ 2\pi i S_N(w) = \int_C S_N(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z \]
since the integrand has a simple pole at $z = 0$ with residue $S_N(0+w) N^0 = S_N(w)$. Note that 
\[ C = A \cup (-A) \cup \{iR, -iR\}. \]
Therefore, we see that 
\[ 2\pi i S_N(w) = \int_A S_N(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z 
+ \int_{-A} S_N(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z. \]
Consider the second integral above. Using the change of variables $z \to -z$, we find that 
\[ \int_{-A} S_N(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z 
= \int_A S_N(-z+w) N^{-z} \left( \frac1z + \frac z{R^2} \right) \dd z. \]
Thus, we obtain 
\[ 2\pi i S_N(w) = \int_A \left( S_N(z+w) N^z + S_N(-z + w) N^{-z} \right) \left( \frac1z + \frac{z}{R^2} \right)\dd z. \]
Combining the above equality with $\eqref{eq:3.2}$, we have 
\begin{align*}
    2\pi i(F(w) - S_N(w)) 
    &= \int_A \left( R_N(z+w) N^z - S_N(-z+w) N^{-z} \right) 
    \left( \frac1z + \frac z{R^2} \right) \dd z \\ 
    &\hspace{1.5cm} + \int_B F(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z. 
    \tag{3.3}\label{eq:3.3}
\end{align*}  
Our goal is to show that $S_N(w)$ converges to $F(w)$ as $N \to \infty$. Write $z = x + iy$
where $x, y \in \R$. Then for $z \in A$, we have $x > 0$ and $|z| = R$, so 
\[ \frac1z + \frac z{R^2} = \frac{x-iy}{R^2} + \frac{x + iy}{R^2} = \frac{2x}{R^2}. \]
Since $|n^z| = n^x$, we have 
\[ |R_N(z+w)| \leq \sum_{n=N+1}^\infty \frac{1}{n^{\Re(z+w)}} \leq \sum_{n=N+1}^\infty 
\frac{1}{n^{x+1}} \leq \int_N^\infty \frac{1}{u^{x+1}}\dd u = \frac{1}{xN^x}. \]
Also, we have 
\[ |S_N(-z+w)| \leq \sum_{n=1}^N \frac{1}{n^{-x+1}} \leq N^{x-1} + \int_1^N u^{x-1}\dd u 
\leq N^{x-1} + \frac{N^x}{x} = N^x \left( \frac1N + \frac1x \right). \]
Putting the above estimates together, we get 
\begin{align*}
    \left| \int_A \left( R_N(z+w) N^z - S_N(-z+w) N^{-z} \right) \left( \frac1z + \frac z{R^2} \right) \dd z \right| 
    &\leq \int_A \left( \frac{1}{xN^x} N^x + N^x \left( \frac1N + \frac1x \right) N^{-x} \right) 
    \frac{2x}{R^2}\dd z \\
    &= \int_A \left( \frac2x + \frac1N \right) \frac{2x}{R^2}\dd z \\
    &= \int_A \left( \frac4{R^2} + \frac{2x}{NR^2} \right)\dd z \\
    &\leq \pi R \left( \frac4{R^2} + \frac{2}{NR} \right) \quad \text{(since $x \leq R$)} \\
    &\leq \frac{4\pi}R + \frac{2\pi}N. 
\end{align*}
We now estimate the integral along $B$. We can divide $B$ into two parts; one part with $\Re(z) = 
-\delta$, and the other with $-\delta < \Re(z) \leq 0$. For $z \in B$ with $\Re(z) = -\delta$, 
we use the fact that $|z| \leq R$ to find that 
\[ \left| \frac1z + \frac z{R^2} \right| = \left| \frac1z \right| \left| \frac{\bar z}{z} + 
\frac{z\bar z}{R^2} \right| \leq \frac1\delta \left( 1 + \frac{|z|^2}{R^2} \right) \leq \frac2\delta. \]
Since $|F(z+w)| \leq M$ for $z \in B$, we have 
\begin{align*}
    \left| \int_B F(z+w) N^z \left( \frac1z + \frac z{R^2} \right)\dd z \right| 
    &\leq \int_{-R}^R MN^{-\delta} \frac2\delta\dd z + 2 \left| \int_{-\delta}^0 MN^x \frac{2x}{R^2}\dd x \right| \\
    &= \frac{4MR}{\delta N^\delta} + \frac{4M}{R^2} \left| \int_{-\delta}^0 xN^x \dd x \right| \\
    &\leq \frac{4MR}{\delta N^\delta} + \frac{4M\delta}{R^2} \left( \frac1{(\log N)^2} - \frac{\delta+1}{N^\delta \log N} \right) \\
    &\leq \frac{4MR}{\delta N^\delta} + \frac{4M\delta}{R^2(\log N)^2}. 
\end{align*}
Combining this estimate with $\eqref{eq:3.2}$ and $\eqref{eq:3.3}$ yields 
\[ |2\pi i(F(w) - S_N(w))| \leq \frac{4\pi}R + \frac{2\pi}N + \frac{4MR}{\delta N^\delta} 
+ \frac{4M\delta}{R^2(\log N)^2}. \] 
That is, we have 
\[ |F(w) - S_N(w)| \leq \frac2R + \frac1N + \frac{MR}{\delta N^\delta} + \frac{M\delta}{R^2(\log N)^2}. \]
Given $\eps > 0$, choose $R = 3/\eps$. Then for sufficiently large $N$, we have 
\[ |F(w) - S_N(w)| < \eps. \]
This implies that $S_N(w) \to F(w)$ as $N \to \infty$, which completes the proof. 
\end{pf}

\subsection{Revisiting the M\"obius Function}\label{subsec:3.3}
Recall that we defined the M\"obius function $\mu : \N \to \{-1, 0, 1\}$ by 
\[ \mu(n) = \begin{cases} 1 & \text{if } n = 1, \\ 0 & \text{if $n$ is not squarefree,} \\ (-1)^r & \text{if $n$ is the product of $r$ distinct primes.} \end{cases} \]
We will show on Homework 2 that for $\Re(s) > 1$, we have 
\[ \frac1{\zeta(s)} = \prod_p \left( 1 - \frac1{p^s} \right) = \sum_{n=1}^\infty \frac{\mu(n)}{n^s}. \]

\begin{thm}\label{thm:3.6}
We have 
\[ \sum_{n=1}^\infty \frac{\mu(n)}n = 0. \]
\end{thm}
\begin{pf}
For all $\Re(s) > 1$, equation (3.4) holds. Moreover, we have shown that $(s-1)\zeta(s)$ is analytic 
and non-zero in $\Re(s) \geq 1$, so $1/\zeta(s)$ is analytic on $\Re(s) \geq 1$. 
Now, $\zeta(s)$ can be analytically continued up to $\Re(s) > 0$ and it is nonzero for $\Re(s) \geq 1$,
so we see that the series 
\[ \sum_{n=1}^\infty \frac{\mu(n)}{n^s} \] 
converges to $1/\zeta(s)$ for $\Re(s) \geq 1$. In particular, it converges at $s = 1$. But 
$\zeta(s)$ has a simple pole at $s = 1$, so $1/\zeta(1) = 0$. 
\end{pf}

\begin{thm}\label{thm:3.7}
We have 
\[ \sum_{n\leq x} \mu(n) = o(x). \]
\end{thm}
\begin{pf}
Applying Abel's summation formula with $a_n = \mu(n) / n $ and $f(x) = x$, we obtain 
\[ \sum_{n\leq x} \mu(n) = A(x)x - \int_1^x A(u)\dd u, \]
where we hae 
\[ A(t) = \sum_{n\leq t} \frac{\mu(n)}n. \]
By Theorem~\ref{thm:3.5}, we know that $A(t) = o(1)$. It follows that $A(x) x = o(x)$ and 
\[ \int_1^x A(u)\dd u = o(x), \]
so the result holds. 
\end{pf}

\subsection{Divisor Function}\label{subsec:3.4}

\begin{defn}\label{def:3.8}
For a positive integer $n \in \N$, let $d(n)$ be the number of positive integers that 
divide $n$. 
\end{defn}

For example, we have $d(1) = 1$, $d(4) = 3$, and $d(p) = 2$ for all primes $p$. 

\begin{thm}\label{thm:3.9}
We have 
\[ \sum_{m=1}^n d(m) = \sum_{m=1}^n \floor*{\frac nm} = n\log n + (2\gamma - 1)n + O(n^{1/2}). \]
where $\gamma$ denotes Euler's constant. 
\end{thm}
\begin{pf}
Let $D_n$ be the region in the upper right-hand quadrant not containing the $x$ or $y$ axes, 
which is under and includes the hyperbola $xy = n$. That is, 
\[ D_n := \{(x, y) \in \R^2 : x > 0,\, y > 0,\, xy \leq n\}. \]
Define a {\bf lattice point} to be a point in the plane with integer coordinates; that is, a point 
$(x, y) \in \R^2$ with $x, y \in \Z$. Notice that every lattice point in $D_n$ is contained in 
some hyperbola $xy = s$ where $s$ is an integer with $1 \leq s \leq n$. 

Therefore, $\sum_{s=1}^n d(s)$ is the number of lattice points in $D_n$; that is, 
\[ \sum_{s=1}^n d(s) = \#\{(x, y) \in \R^2 : x, y \in \N,\, xy \leq n\}. \]
We now count the number of lattice points in a different way. Given $x \in \N$ with $1 \leq x \leq n$, 
there are exactly $\floor{\frac xn}$ many integers $y$ such that $xy \leq n$. Thus, we see that 
\[ \#\{(x, y) \in \R^2 : x, y \in \N,\, xy \leq n\} = \sum_{x=1}^n \floor*{\frac nx}. \]
Observe that the number of lattice points above the line $x = y$ inside $D_n$ is equal to the number of 
lattice points below it. Divide the lattice points in $D_n$ into three disjoint regions given by 
\begin{align*}
    D_{n,1} &= \{(x, y) \in \N^2 : xy \leq n,\, x < y\}, \\ 
    D_{n,2} &= \{(x, y) \in \N^2 : xy \leq n,\, x > y\}, \\
    D_{n,3} &= \{(x, y) \in \N^2 : xy \leq n,\, x = y\}.
\end{align*}
Our observation above shows that $|D_{n,1}| = |D_{n,2}|$. Suppose that $(x, y) \in D_{n,1}$. Then 
$x^2 < xy \leq n$, which implies that $x < \sqrt n$. Moreover, for a fixed integer $x$, the number of 
integers $y$ satisfying $xy \leq n$ and $y > x$ is $\floor{\frac nx} - \floor x$. We also see that 
$|D_{n,3}| = \floor{\sqrt n}$, so we obtain 
\begin{align*}
    \sum_{x=1}^n \floor*{\frac nx} &= |D_{n,1}| + |D_{n,2}| + |D_{n,3}| \\
    &= 2 \sum_{x=1}^{\floor{\sqrt n}} \left( \floor*{\frac nx} - \floor x \right) + \floor{\sqrt n} \\
    &= 2 \sum_{x=1}^{\floor{\sqrt n}} \left( \frac nx - x + O(1) \right) + \floor{\sqrt n}. 
\end{align*}
By Theorem~\ref{thm:2.10}, we see that 
\[ \sum_{x=1}^n \floor*{\frac nx} = 2n \left( \log\floor{\sqrt n} + \gamma + O\left( \frac1{\sqrt n} \right) \right) - \left( n + O(\sqrt n) \right) + O(\sqrt n). \]
Note that if we use the fact that $\log\floor{\sqrt n} = \log \sqrt n + O(1)$, then the resulting 
error term $O(n)$ will be too large. Therefore, we need a finer estimate. Indeed, since 
$\floor{\sqrt n} = \sqrt n - \{\sqrt n\}$ where $\{t\}$ denotes the fractional part of $t$ for 
$t \in \R$, we have 
\begin{align*} \log \floor{\sqrt n} = \log \left( \sqrt n - \{\sqrt n\} \right) 
&= \log \left( \sqrt n \left( 1 - \frac{\{\sqrt n\}}{\sqrt n} \right) \right) \\
&= \log \sqrt n + \log \left( 1 - \frac{\{\sqrt n\}}{\sqrt n} \right) \\
&= \log \sqrt n + O\left( \frac1{\sqrt n} \right). \end{align*}
Combining this with the previous equality gives 
\[ \sum_{x=1}^n \floor*{\frac nx} = n\log n + (2\gamma - 1)n + O(\sqrt n). \qedhere \]
\end{pf}

\subsection{The Prime Number Theorem}\label{subsec:3.5}
We now have everything we need to prove the Prime Number Theorem. 

\begin{thm}[Prime Number Theorem]\label{thm:3.10}
    We have 
    \[ \pi(x) \sim \frac{x}{\log x}. \] 
\end{thm}
\begin{pf}
    In Theorem~\ref{thm:2.7}, we showed that 
    \[ \pi(x) \sim \frac{\psi(x)}{\log x}. \] 
    Therefore, it suffices to show that $\psi(x) \sim x$. Define the function 
    \[ F(x) = \sum_{n\leq x} \left( \psi\left( \frac xn \right) - \floor*{\frac xn}
    + 2\gamma \right), \] 
    where $\gamma$ denotes Euler's constant. By the M\"obius inversion formula 
    (Proposition~\ref{prop:2.5}), we have 
    \[ \psi(x) - \floor{x} + 2\gamma = \sum_{n\leq x} \mu(n) F\left( \frac xn \right). \] 
    In particular, we get 
    \[ \psi(x) = x + O(1) + \sum_{n \leq x} \mu(n) F\left( \frac xn \right). \] 
    Now, it is enough to show that $\sum_{n\leq x} \mu(n) F(x/n) = o(x)$. First, 
    we will estimate $F(x)$. Observe that 
    \[ F(x) = \sum_{n\leq x} \psi\left( \frac xn \right) - \sum_{n \leq x} 
    \floor*{\frac xn} + 2\gamma\floor{x}. \tag{3.4}\label{eq:3.4} \]
    Looking at the first sum in $\eqref{eq:3.4}$, we have 
    \begin{align*}
        \sum_{n\leq x} \psi\left( \frac xn \right) 
        &= \sum_{n \leq x} \sum_{m \leq \frac xn} \Lambda(m) \\
        &= \sum_{n \leq x} \Lambda(n) \sum_{m\leq \frac xn} 1 \\
        &= \sum_{n \leq x} \Lambda(n) \floor*{\frac xn} \\
        &= \sum_{p^k \leq x} \log p \floor*{\frac x{p^k}} \\ 
        &= \sum_{p \leq x} \left( \floor*{\frac xp} + \floor*{\frac x{p^2}} 
        + \cdots + \floor*{\frac x{p^k}} \right) \quad \text{(where $p^k\;\|\;\floor{x}$)} \\
        &= \log(\floor{x}!) = \sum_{n \leq x} \log n. 
    \end{align*}
    In the proof of Theorem~\ref{thm:2.11}, we showed that 
    \[ \sum_{n\leq x} \log n = x\log x - x + O(\log x). \] 
    Hence, we obtain 
    \[ \sum_{n\leq x} \psi\left( \frac xn \right) = x\log x - x + O(\log x). \tag{3.5}\label{eq:3.5} \] 
    Moreover, by Theorem~\ref{thm:3.9}, we have 
    \[ \sum_{n=1}^{\floor{x}} \floor*{\frac{\floor x}n} = \floor{x}\log\floor{x} 
    + (2\gamma - 1)\floor{x} + O(x^{1/2}). \] 
    For all $y \in \R$, notice that $\floor{y} \leq y \leq \floor{y}+1$. In particular, 
    we obtain the inequalities 
    \[ \sum_{n=1}^{\floor{x}} \floor*{\frac{\floor{x}}n} \leq 
    \sum_{n=1}^{\floor{x}} \floor*{\frac{x}n} \leq 
    \sum_{n=1}^{\floor{x}+1} \floor*{\frac{\floor{x}+1}n}, \] 
    and it follows that 
    \[ \sum_{n=1}^{\floor{x}} \floor*{\frac{x}{n}} = x\log x + (2\gamma - 1) 
    + O(x^{1/2}). \tag{3.6}\label{eq:3.6} \] 
    Combining equations $\eqref{eq:3.4}$, $\eqref{eq:3.5}$, and $\eqref{eq:3.6}$ gives 
    \[ F(x) = (x\log x - x + O(\log x)) - (x\log x + (2\gamma-1)x + O(x^{1/2})) 
    + (2\gamma x + O(1)) = O(x^{1/2}). \] 
    Therefore, there exists a positive constant $c > 0$ such that 
    \[ |F(x)| \leq cx^{1/2} \] 
    for all $x \geq 1$. If $t > 1$ is an integer, then 
    \begin{align*}
        \left| \sum_{n\leq \frac xt} \mu(n) F\left( \frac xn \right) \right| 
        &\leq \sum_{n\leq \frac xt} \left| F\left( \frac xn \right) \right| \\ 
        &\leq \sum_{n\leq \frac xt} c\left( \frac xn \right)^{\!1/2} \\
        &\leq cx^{1/2} \left( 1 + \int_1^{x/t} \frac{1}{u^{1/2}}\dd u \right) \\
        &= cx^{1/2} \left(1 + 2 \left( \frac xt \right)^{\!1/2} - 2 \right) \\ 
        &\leq 2 \cdot \frac{cx}{t^{1/2}}. \tag{3.7}\label{eq:3.7}
    \end{align*}
    Observe that $F$ is a step function. That is, if $a$ is an integer and 
    $a \leq x < a + 1$, then $F(x) = F(a)$. Therefore, we have 
    \[ \sum_{\frac xt < n \leq x} \mu(n) F\left(\frac xn \right) 
    = F(1) \sum_{\frac x2 < n \leq x} \mu(n) + F(2) \sum_{\frac x3 < n \leq 
    \frac x2} \mu(n) + \cdots + F(t-1) \sum_{\frac xt < n \leq \frac{x}{t-1}} \mu(n). \] 
    We see that 
    \begin{align*}
        \left| \sum_{\frac xt < n \leq x} \mu(n) F\left(\frac xn \right) \right| 
        &\leq |F(1)| \left| \sum_{\frac x2 < n \leq x} \mu(n) \right| + 
        |F(2)| \left| \sum_{\frac x3 < n \leq \frac x2} \mu(n) \right| + \cdots + 
        |F(t-1)| \left| \sum_{\frac xt < n \leq \frac{x}{t-1}} \mu(n) \right| \\ 
        &\leq (|F(1)| + \cdots + |F(t-1)|) \max_{2\leq i \leq t} 
        \left| \sum_{\frac xi < n \leq \frac{x}{i-1}} \mu(n) \right| \\ 
        &\leq \left( \sum_{i=1}^t ci^{1/2} \right) \max_{2\leq i \leq t} 
        \left| \sum_{\frac xi < n \leq \frac{x}{i-1}} \mu(n) \right|. 
    \end{align*}
    Notice that 
    \[ \sum_{\frac xi < n \leq \frac{x}{i-1}} \mu(n) = 
    \sum_{n \leq \frac{x}{i-1}} \mu(n) - \sum_{\frac{x}{i} < n} \mu(n) = o(x), \] 
    so we obtain 
    \[ \left| \sum_{\frac xt < n \leq x} \mu(n) F\left( \frac xn \right) \right| 
    = o(t^{3/2}x). \] 
    By Theorem~\ref{thm:3.7}, we have $\sum_{n\leq x} \mu(n) = o(x)$. Hence, 
    for any $\eps > 0$, we can find sufficiently large $x$ such that 
    \[ -\eps x \leq \sum_{n\leq x} \mu(n) \leq \eps x. \] 
    In particular, when $x$ is sufficiently large, we get 
    \[ -\frac{\eps x}{i-1} - \frac{\eps x}{i} 
    \leq \sum_{\frac{x}{i} < n \leq \frac{x}{i-1}} \mu(n) 
    \leq \frac{\eps x}{i-1} + \frac{\eps x}{i}. \] 
    For any given $\eps > 0$, choose $t = t(\eps)$ such that 
    \[ \frac{2c}{t^{1/2}} < \frac{\eps}2. \] 
    By equation $\eqref{eq:3.7}$, we have 
    \[ \left| \sum_{n\leq \frac{x}{t}} \mu(n) F\left( \frac xn \right) \right| 
    \leq 2 \cdot \frac{cx}{t^{1/2}} < \frac{\eps}2 x. \tag{3.8}\label{eq:3.8} \] 
    For fixed $\eps > 0$ and $t$ as above, we can choose $x$ sufficiently large 
    so that $o(xt^{3/2}) \leq \eps x/2$. Indeed, we have 
    $2c/t^{1/2} < \eps/2$ if and only if $t > (4c)^2/\eps^2$. In particular, 
    we have $t = A^2\eps^{-2}$ for some $A > 4c$, and we can pick $x$ large 
    enough so that 
    \[ o(x) \leq \frac{\eps^4}{2A^3}x. \] 
    Then we get 
    \[ o(xt^{3/2}) \leq \frac{\eps^4}{2A^3} x \cdot A^3\eps^{-3} = \frac{\eps}2 x. \] 
    It follows that 
    \[ \left| \sum_{\frac xt < n \leq x} \mu(n) F\left( \frac xn \right) \right| < 
    \frac{\eps}2. \tag{3.9}\label{eq:3.9} \] 
    Combining inequalities $\eqref{eq:3.8}$ and $\eqref{eq:3.9}$ yields 
    \[ \left| \sum_{n\leq x} \mu(n) F\left( \frac xn \right) \right| = o(x), \] 
    which completes the proof. 
\end{pf}

\begin{remark}\label{remark:3.11}~
    \begin{enumerate}[(1)]
        \item In 1896, Hadamard and de la Vall\'ee Poussin proved the Prime 
        Number Theorem independently. Consider the logarithmic integral 
        \[ \Li(x) = \int_2^x \frac{1}{\log t}\dd t \sim \frac{x}{\log x} 
        \sum_{k=0}^\infty \frac{k!}{(\log x)^k}. \] 
        In 1899, de la Vall\'ee Poussin proved that as $x \to \infty$, there 
        exists some $a > 0$ such that 
        \[ \pi(x) = \Li(x) + O(xe^{-a\sqrt{\log x}}). \]
        \item The main ingredient of our proof of the Prime Number Theorem is the 
        fact that $\sum_{n\leq x} \mu(n) = o(x)$, which is a consequence of the 
        analytic continuation and non-vanishing of $\zeta(s)$ at $\Re(s) = 1$. 
        The {\bf Riemann hypothesis}, proposed by Riemann in 1859, states that 
        the non-trivial zeros of $\zeta(s)$ all have real part $1/2$. 
        (The trivial zeros of $\zeta(s)$ are of the form $2n$ for $n \in \Z$ and 
        $n < 0$; these can be obtained by functional equations.) In 1901, Helge von 
        Koch proved that the Riemann hypothesis is true if and only if 
        \[ \pi(x) = \Li(x) + O(\sqrt x \log x). \] 
    \end{enumerate}
\end{remark}
