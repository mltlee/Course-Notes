\section{Minimum Spanning Trees}\label{sec:2}

\subsection{Trees}\label{subsec:2.1}
A {\bf tree} is a connected acyclic graph; that is, a connected graph 
containing no cycles. 
\begin{center}
    \begin{tikzpicture}[node distance={15mm}, main/.style = {draw, circle}] 
        \node[main] (1) {}; 
        \node[main] (2) [below right of=1] {};
        \node[main] (3) [below left of=2] {}; 
        \node[main] (4) [below right of=2] {};
        \node[main] (5) [above right of=4] {};
        \node[main] (6) [below of=5] {};
        \node[main] (7) [below right of=5] {};
        \node[main] (8) [right of=5] {};
        \node[main] (9) [above right of=8] {};
        \node[main] (10) [below right of=8] {};

        \draw (1) -- (2); \draw (2) -- (3); \draw (2) -- (4);
        \draw (4) -- (5); \draw (5) -- (6); \draw (5) -- (7);
        \draw (5) -- (8); \draw (8) -- (9); \draw (8) -- (10);
    \end{tikzpicture} 
\end{center}
\vspace{-0.25cm}
Given a graph $G = (V, E)$, a {\bf spanning tree} of $G$ is a graph $T = (V, F)$ 
such that $F \subseteq E$ and $T$ is a tree. We illustrate an example of a 
graph $G$ with a subtree $T$ using bold edges below. 
\begin{center}
    \begin{tikzpicture}[node distance={15mm}, main/.style = {draw, circle}] 
        \node[main] (1) {}; 
        \node[main] (2) [right of=1] {};
        \node[main] (3) [below left of=1] {}; 
        \node[main] (4) [below right of=2] {};
        \node[main] (5) [below right of=3] {};
        \node[main] (6) [right of=5] {};
        \node[main] (7) [right of=6] {};

        \draw (1) -- (2); 
        \draw (1) -- (3); 
        \draw [line width=2pt] (1) -- (6);
        \draw (1) -- (7);
        \draw [line width=2pt] (2) -- (4);
        \draw (2) to [out=0, in=45, looseness=2] (7);
        \draw [line width=2pt] (3) -- (5);
        \draw [line width=2pt] (4) -- (7);
        \draw [line width=2pt] (5) -- (6);
        \draw [line width=2pt] (6) -- (7);
    \end{tikzpicture} 
\end{center}
In an introductory graph theory course, such as MATH 239, 
it is shown that every tree on $n$ vertices has $n-1$ edges. The following 
theorem then gives us a useful characterization of trees. 

\begin{theo}[Fundamental Theorem of Trees]{theo:2.1}
    Let $T = (V, F)$ be a graph. The following are equivalent:
    \begin{enumerate}[(i)]
        \item $T$ is a tree. 
        \item $T$ is connected and $|F| = |V| - 1$. 
        \item $T$ is acyclic and $|F| = |V| - 1$. 
    \end{enumerate}
\end{theo}\vspace{-0.25cm}

In particular, if we know that two of the conditions hold, then the 
third one is guaranteed.

\subsection{Minimum Spanning Trees}\label{subsec:2.2}
Given a connected graph $G = (V, E)$ and edge costs $c_e$ for each 
$e \in E$, our goal is to find a spanning tree $T$ of minimum cost 
\[ c(T) := \sum_{e \in T} c_e. \] 
First, we'll set some notation. For a vertex $v \in V$, we define 
$\delta(v)$ to be the set of edges in $E$ incident to $v$. More generally, 
given a subset of vertices $S \subseteq V$, the {\bf cut induced by $S$} is 
defined to be the set 
\[ \delta(S) := \{uv \in E : u \in S,\, v \notin S\}. \] 
The following theorem will be extremely important for finding a minimum 
spanning tree. 

\begin{theo}[Cut Property]{theo:2.2}
    Suppose that the costs $c_e$ for $e \in E$ are distinct. 
    Let $S \subseteq V$ be such that $S \neq \varnothing$ and $S \neq V$, 
    and let 
    \[ e = \argmin_{f \in \delta(S)} c_f. \] 
    Then every minimum spanning tree contains the edge $e$. 
\end{theo}\vspace{-0.25cm}
\begin{pf}[Theorem~\ref{theo:2.2}]
    We proceed by contradiction. Let $S \subseteq V$ be such that $S 
    \neq \varnothing$ and $S \neq V$, and let $e = \argmin_{f\in S} c_f$. 
    Suppose that there is a minimum spanning tree $T = (V, F)$ such that 
    $e \notin F$. 

    Consider the graph $(V, F \cup \{e\})$. Note that $|F \cup \{e\}| = |V|$ 
    and this graph is connected, so it cannot be a tree by Theorem~\ref{theo:2.1}. 
    In particular, it must contain a cycle $C$. 

    Next, note that $|C \cap \delta(S)|$ must be even because for any 
    edge leaving the cut $\delta(S)$, there must be another edge coming back 
    into the cut. Moreover, since $e \in C \cap \delta(S)$, we have 
    $C \cap \delta(S) \neq \varnothing$. This implies that 
    $|C \cap \delta(S)| \geq 2$, so there is another edge $e' \neq e$ 
    with $e' \in C \cap \delta(S)$.

    Consider now the graph $T' = (V, (F \cup \{e\}) \setminus \{e'\})$. 
    Then $|(F \cup \{e\}) \setminus \{e'\}| = |F| = |V| - 1$ and $T'$ is 
    connected because if a path between two vertices used the edge $e'$, 
    then we could go along the edges in $C \setminus \{e'\}$ instead. 
    So by Theorem~\ref{theo:2.1}, $T'$ is also a spanning tree. 
    Finally, observe that 
    \[ c(T) - c(T') = c_{e'} - c_e > 0 \] 
    because we have $e = \argmin_{f\in S} c_f$ and $e' \neq e$ with 
    $e' \in \delta(S)$, and the edge 
    costs $c_e$ for $e \in E$ are distinct. But $c(T') < c(T)$, contradicting 
    our assumption that $T$ was a minimum 
    spanning tree. \qed
\end{pf}\vspace{-0.25cm}

The following property relating cycles to minimum spanning trees 
can also be proved similarly to Theorem~\ref{theo:2.2}. 

\begin{theo}[Cycle Property]{theo:2.3}
    Let $G = (V, E)$ be connected with distinct edge costs 
    $c_e$ for $e \in E$. Let $C$ be a cycle in $G$ and let 
    \[ e = \argmax_{f\in C} c_f. \] 
    Then no minimum spanning tree contains the edge $e$. 
\end{theo}\vspace{-0.25cm}
\begin{pf}[Theorem~\ref{theo:2.3}]
    Let $T = (V, F)$ be a spanning tree containing $e$, 
and suppose that the endpoints of $e$ are $v$ and $w$. We show that $T$ 
does not have the smallest possible cost. Similar to the proof of the 
cut property, we do this by exchanging $e$ with an edge $e'$ 
of cheaper cost in a way that we still obtain a spanning tree. 

By deleting $e$ from $T$, we obtain a graph with two components: $S$ 
containing $v$ and $V \setminus S$ containing $w$. The edge we are 
replacing $e$ with should have one end in $S$ and the other in $V \setminus S$ 
to connect the components back together. 

To find such an edge, we follow the cycle $C$. Note that the edges in 
$C \setminus \{e\}$ together form a path $P$ from $v$ to $w$. If 
we follow $P$ from $v$ to $w$, we will begin at $S$ and end in $V \setminus S$, 
so there is some edge $e'$ in $P$ that crosses from $S$ to $V \setminus S$. 
Let $T' = (V, (F \cup \{e'\}) \setminus \{e\})$. Note that $T'$ 
has $|V| - 1$ edges and is connected by our above argument, so it is a tree 
by the fundamental theorem of trees. Moreover, we have $c_{e'} < c_e$ 
since $e$ is the edge of maximum cost in $C$ with $e' \in C$ so that 
$c(T) - c(T') = c_e - c_{e'} > 0$.
Then $c(T) > c(T')$, so $T'$ is a spanning tree of $G$ with smaller cost 
than $T$. It follows that $T$ is not a minimum spanning tree. \qed
\end{pf}\vspace{-0.25cm}

\subsection{Prim's Algorithm}\label{subsec:2.3}
Prim's algorithm takes the idea of the cut property (Theorem~\ref{theo:2.2}) 
and uses it to compute a minimum spanning tree starting from an arbitrary 
vertex $s \in V$. At each iteration of the algorithm, we will keep track of a 
set of a partial tree construction $T$ and vertices $A \subseteq V$ that are 
connected to $s$ in $T$. We finish once we have reached all the vertices in $G$.

\begin{mdframed}[
    linewidth=1pt,
    linecolor=black,
    bottomline=false,topline=false,rightline=false,
    innerrightmargin=0pt,innertopmargin=0pt,innerbottommargin=0pt,
    innerleftmargin=1em,% Distance between vertical rule & proof content
    skipabove=0.75\baselineskip
]
{\bf Input.} A connected graph $G = (V, E)$ and edge costs $c_e$ for 
all $e \in E$. 

{\bf Output.} The edges $T$ of a minimum spanning tree of $G$.
\begin{enumerate}[leftmargin=1.75cm, label={Step \arabic*.}]
    \item {\bf (Initialization.)} Let $s \in V$ be an arbitrary vertex, 
    then set $A \gets \{s\}$ and $T \gets \varnothing$.

    \item While $A \neq V$:
    \begin{enumerate}[label={Step 2.\arabic*.}]
        \item {\bf (Pick an edge for the minimum spanning tree.)} 
        Set 
        \[ e \gets \argmin_{f \in \delta(A)} c_f, \] 
        where $e = uv$ with $u \in A$ and $v \notin A$.  
        \item {\bf (Update values.)} Set $A \gets A \cup \{v\}$ and 
        $T \gets T \cup \{e\}$. 
    \end{enumerate}
\end{enumerate}
\end{mdframed}\vspace{-0.15cm}

Let's run Prim's algorithm on a simple example. Consider the following 
graph $G = (V, E)$, and suppose that at Step 1, we pick $v_1$ to be 
the initial vertex. 
\begin{center}
    \begin{tikzpicture}[node distance={22.5mm}, main/.style = {draw, circle}] 
        \node[main, color=blue] (1) {$v_1$}; 
        \node[main] (2) [right of=1] {$v_2$};
        \node[main] (3) [right of=2] {$v_3$}; 
        \node[main] (4) [below of=1] {$v_4$};
        \node[main] (5) [right of=4] {$v_5$};

        \draw (1) -- node[midway, above] {1} (2);
        \draw (2) -- node[midway, above] {3} (3);
        \draw (1) -- node[midway, left] {4} (4);
        \draw (2) -- node[midway, above left] {2} (4);
        \draw (2) -- node[midway, right] {5} (5);
        \draw (3) -- node[midway, below right] {1} (5);
        \draw (5) -- node[midway, above] {4} (4);
    \end{tikzpicture} 
\end{center}
\vspace{-0.25cm}
Then at the first iteration of Step 2.1, we have $\delta(A) = 
\{v_1v_2, v_1v_4\}$, so we pick $e = v_1v_2$ because it has minimum cost.
At Step 2.2, we set $A = \{v_1, v_2\}$ and $T = \{v_1v_2\}$. 

\begin{center}
    \begin{tikzpicture}[node distance={22.5mm}, main/.style = {draw, circle}] 
        \node[main, color=blue] (1) {$v_1$}; 
        \node[main, color=blue] (2) [right of=1] {$v_2$};
        \node[main] (3) [right of=2] {$v_3$}; 
        \node[main] (4) [below of=1] {$v_4$};
        \node[main] (5) [right of=4] {$v_5$};

        \draw[color=blue] (1) -- node[midway, above] {1} (2);
        \draw (2) -- node[midway, above] {3} (3);
        \draw (1) -- node[midway, left] {4} (4);
        \draw (2) -- node[midway, above left] {2} (4);
        \draw (2) -- node[midway, right] {5} (5);
        \draw (3) -- node[midway, below right] {1} (5);
        \draw (5) -- node[midway, above] {4} (4);
    \end{tikzpicture} 
\end{center}
\vspace{-0.25cm}
The edge $v_2v_4$ is of minimum cost in the cut induced by $A$, so 
we set $A = \{v_1, v_2, v_4\}$ and $T = \{v_1v_2, v_2v_4\}$ at the next iteration. 
Continuing in this fashion, we obtain the following minimum spanning tree.

\begin{center}
    \begin{tikzpicture}[node distance={22.5mm}, main/.style = {draw, circle}] 
        \node[main, color=blue] (1) {$v_1$}; 
        \node[main, color=blue] (2) [right of=1] {$v_2$};
        \node[main, color=blue] (3) [right of=2] {$v_3$}; 
        \node[main, color=blue] (4) [below of=1] {$v_4$};
        \node[main, color=blue] (5) [right of=4] {$v_5$};

        \draw[color=blue] (1) -- node[midway, above] {1} (2);
        \draw[color=blue] (2) -- node[midway, above] {3} (3);
        \draw (1) -- node[midway, left] {4} (4);
        \draw[color=blue] (2) -- node[midway, above left] {2} (4);
        \draw (2) -- node[midway, right] {5} (5);
        \draw[color=blue] (3) -- node[midway, below right] {1} (5);
        \draw (5) -- node[midway, above] {4} (4);
    \end{tikzpicture} 
\end{center}
\vspace{-0.25cm}
Note that Prim's algorithm may seen similar to Dijkstra's algorithm 
which also yields a spanning tree in the process of computing shortest paths. 
However, these algorithms fundamentally solve different problems, and 
there are examples where the resulting spanning trees do not coincide. 
Moreover, Dijkstra's algorithm takes a directed graph as input, 
whereas Prim's algorithm takes an undirected graph. 

Next, let's prove that Prim's algorithm always gives us a minimum spanning tree. 
For simplicity, we will assume that all edge costs $c_e$ for 
$e \in E$ are distinct. 

\begin{pf}[correctness of Prim's algorithm]
    At every iteration of Step 2, we add one edge to $T$, and we run 
    through $|V| - 1$ iterations. Therefore, $T$ has exactly 
    $|V| - 1$ edges. Moreover, an invariant of Prim's algorithm is that 
    all vertices in $A$ remain connected to $s$, so the final output is 
    also connected. Therefore, we indeed obtain a spanning tree by 
    Theorem~\ref{theo:2.1}. Finally, by the cut property (Theorem~\ref{theo:2.2})
    and our assumption that all the edge costs are distinct, $T$ contains 
    only the edges that are in every minimum spanning tree, so $T$ 
    itself is a minimum spanning tree. \qed 
\end{pf}\vspace{-0.25cm}

As a consequence, we also have the following useful result. 

\begin{cor}{cor:2.4}
    Let $G = (V, E)$ be a connected graph with distinct edge costs $c_e$ for 
    $e \in E$. Then $G$ has a unique minimum spanning tree.
\end{cor}\vspace{-0.25cm}

As usual, let's consider the running time, denoting $|V| = n$ 
and $|E| = m$. For an efficient implementation, 
we keep track of a key $d'(v)$ for each $v \in V \setminus A$. 
Once a vertex $w$ is added to $A$ in Step 2.2, we update the keys via 
$d'(v) \gets \min\{d'(v), c_{wv}\}$ for each $v \in V \setminus A$. 

Note that Step 1 takes $O(1)$ time, and 
there are $n-1$ iterations of Step 2. Implementing Prim's algorithm 
using priority queues, we note that each iteration of Step 2.1 
involves one \textsc{Extract-Min} call, and 
going through all iterations of Step 2.2 takes at most $m$ 
\textsc{Decrease-Key} calls in total. We recall that by using Fibonacci heaps, 
\textsc{Decrease-Key} is $O(1)$ and \textsc{Extract-Min} is $O(\log n)$, 
so we have a total running time of $O(n\log n + m)$.

\subsection{Kruskal's Algorithm}\label{subsec:2.4}
Kruskal's algorithm is another greedy algorithm that finds a minimum 
spanning tree. It first sorts the edges by ascending edge costs 
and continually adds an edge to a partial tree construction $T$ as long as no 
cycle is induced by that edge. The algorithm we give stops once we 
go through every edge, but note that it is enough to stop once the 
number of edges we've added hits $|V| - 1$.

\begin{mdframed}[
    linewidth=1pt,
    linecolor=black,
    bottomline=false,topline=false,rightline=false,
    innerrightmargin=0pt,innertopmargin=0pt,innerbottommargin=0pt,
    innerleftmargin=1em,% Distance between vertical rule & proof content
    skipabove=0.75\baselineskip
]
{\bf Input.} A connected graph $G = (V, E)$ and edge costs $c_e$ for 
all $e \in E$. (We write $m = |E|$ and $n = |V|$.)

{\bf Output.} The edges $T$ of a minimum spanning tree of $G$.
\begin{enumerate}[leftmargin=1.75cm, label={Step \arabic*.}]
    \item {\bf (Initialization.)} Sort the edges such that 
    $c_{e_1} \leq c_{e_2} \leq \cdots \leq c_{e_m}$. 
    Set $T \gets \varnothing$ and $j \gets 1$. 

    \item While $j \neq m+1$:
    \begin{enumerate}[label={}]
        \item {\bf (Add an edge if it does not form a cycle.)} 
        If $T \cup \{e_j\}$ is acyclic, set $T \gets T \cup \{e_j\}$. 
        \item {\bf (Go to the next edge.)} Regardless if we add an edge or not, 
        increment $j \gets j+1$. 
    \end{enumerate}
\end{enumerate}
\end{mdframed}\vspace{-0.15cm}

To prove the correctness of Kruskal's algorithm, we'll again use the cut 
property (Theorem~\ref{theo:2.2}). As with Prim's algorithm, the proof will 
consist of two parts: proving that the result $T$ is a spanning tree, and showing 
that it is of minimum cost. We will also assume that the edge costs $c_e$ are 
distinct. 

We use a couple of facts that will be repeated 
many times throughout the course. These concern equivalent 
notions to the definitions we have.
\begin{enumerate}[(1)]
    \item A graph $G = (V, E)$ is disconnected if and only if there exists a 
    nontrivial cut $\delta(S)$ for some $\varnothing \subsetneq S \subsetneq V$ such that 
    $\delta(S) \cap E = \varnothing$. 
    \item Let $G = (V, E)$ be a graph and let $u, v \in V$ be distinct vertices. 
    Then $G$ has no $u, v$-path if and only if there exists $S \subseteq V$ 
    such that $u \in S$, $v \notin S$, and $\delta(S) \cap E = \varnothing$. 
\end{enumerate}
\begin{pf}[correctness of Kruskal's algorithm]
    Let $T$ denote the output set consisting of edges. We know that $T$ is 
    acyclic by construction because Step 2 of the algorithm rules 
    out all edges that create a cycle. We will show that $(V, T)$ is 
    connected by way of contradiction, and thus it is a spanning tree 
    by Theorem~\ref{theo:2.1}.

    Suppose not, so there is a nontrivial cut $\delta(S)$ for some $\varnothing \subsetneq S 
    \subsetneq V$ such that $\delta(S) \cap T = \varnothing$ by (1) above. 
    Since $G$ is connected, we have $\delta(S) \neq \varnothing$, so 
    there exists some edge $e \in \delta(S)$. 
    Let's look at the moment where $e$ was considered in the algorithm. 
    Since $e$ was rejected, it must be that $T \cup \{e\}$ contains a cycle 
    $C$ with $e \in C$. But $|C \cap \delta(S)|$ is even and $e \in 
    C \cap \delta(S)$, so $|C \cap \delta(S)| \geq 2$. We then have 
    $|(C \setminus \{e\}) \cap \delta(S)| \geq 1$. But $C \setminus \{e\} 
    \subseteq T$, which contradicts the fact that $\delta(S) \cap T = \varnothing$. 

    Now, we show that we have a minimum spanning tree. Consider the moment 
    an arbitrary edge $e = uv$ is added to $T$; let $T'$ be the set of edges 
    in $T$ before the addition of $e$ to $T$. Then $T'$ has no $u, v$-path 
    (else a $u, v$-path adjoined with $e$ would form a cycle). Hence, 
    by (2), there exists $S \subseteq V$ such that $u \in S$, $v \notin S$, 
    and $\delta(S) \cap T' = \varnothing$. Due to the way that the edges 
    are sorted in Step 1, we have $e = \argmin_{f\in\delta(S)} c_f$. 
    It follows from the cut property (Theorem~\ref{theo:2.2}) that including 
    $e$ is the correct decision. \qed
\end{pf}\vspace{-0.25cm}

To implement Kruskal's algorithm, first observe that Step 1 takes 
$O(m\log m)$ time to sort $m$ numbers. For Step 2, we can make use 
of the {\sc UnionFind} data structure, which helps maintain a 
list of connected components. It has the following methods:
\begin{itemize}
    \item {\sc MakeUnionFind}$(V)$ creates a {\sc UnionFind} data structure 
    for $V$ and takes $O(n)$ time. 
    \item {\sc Find}$(v)$ determines the name of the connected component where 
    $v$ lies. This takes $O(\log n)$. 
    \item {\sc Union}$(A, B)$ merges two connected components and takes 
    $O(1)$ via a change of pointer. 
\end{itemize}
We initialize the data structure once with \textsc{MakeUnionFind}.
We use {\sc Find} in every iteration of Step 2 to check that 
$\textsc{Find}(u) \neq \textsc{Find}(v)$ for the edge $e = uv$. In this 
case, $u$ and $v$ are in different components and we can join them with 
{\sc Union}; otherwise we don't have to do anything. There are $m$ iterations 
of Step 2, so Kruskal's algorithm takes $O(m\log n) = O(m\log m)$ 
time (since $n-1 \leq m \leq n^2$ when $G$ is connected).

\subsection{Maximum Spacing Clustering}\label{subsec:2.5}
We are given a set $U = \{p_1, \dots, p_n\}$
of $n$ objects and a distance $d(p_i, p_j)$ between points. 
We require that $d(p_i, p_i) = 0$ and $d(p_i, p_j) = d(p_j, p_i) > 0$ 
for distinct $p_i$ and $p_j$. A {\bf $k$-clustering} of $U$ is a 
partition of $U$ into $k$ nonempty sets $C_1, \dots, C_k$. 
The {\bf spacing} of a $k$-clustering is the minimum distance 
between any pair of points lying in different clusters. We want 
points in different clusters to be far apart from each other, 
so a natural goal is to seek the $k$-clustering 
with the maximum possible spacing. That is, over all 
$k$-clusterings $C_1, \dots, C_k$ of $U$, we want to maximize 
\[ \min_{1\leq i < j\leq k} \left\{ \min_{p\in C_i, q\in C_j} d(p, q) \right\}. \]

{\bf Single linkage clustering algorithm.} Consider the complete
graph $K_n$ on the vertex set $U$ with the edge costs given by 
the distances. The connected components will be the clusters. 
We want to bring nearby points together into the 
same cluster as rapidly as possible so that they don't end up 
in different clusters that are close together. We see that 
if we sort by ascending distances and skip over edges where 
both endpoints are already in the same cluster, then we avoid 
cycles and end up with a union of trees. 

Note that this procedure is precisely Kruskal's algorithm. The only difference 
is that we are looking for a $k$-clustering, so we stop once we hit $k$ 
connected components. That is, we 
are running Kruskal's algorithm but stopping it before it 
adds the last $k-1$ edges. This is equivalent to taking the 
full minimum spanning tree and deleting the $k-1$ most expensive edges 
and defining the $k$-clustering to be the resulting connected 
components $C_1, \dots, C_k$. We show that this is a 
$k$-clustering of maximum spacing.

\begin{pf}[correctness of the single linkage clustering algorithm] 
Let ${\cal C}$ denote the clustering 
$C_1, \dots, C_k$. The spacing of ${\cal C}$ is the length 
$d^*$ of the $(k-1)$-th most expensive edge in the minimum spanning tree; 
this is the length of the edge that Kruskal's algorithm would have added 
next at the moment we stopped it. 

Let ${\cal C}'$ be another $k$-clustering which partitions $U$ 
into nonempty sets $C'_1, \dots, C'_k$. We show that the spacing of ${\cal C}'$ 
is at most $d^*$.
Since ${\cal C}$ and ${\cal C}'$ are not equal, it must be that one of 
the clusters $C_r$ is not a subset of any of the $k$ sets $C'_s$ in ${\cal C}'$. 
Hence, there are points $p_i, p_j \in C_r$ that belong to different 
clusters in ${\cal C}'$, say $p_i \in C'_s$ and $p_j \in C'_t$ with 
$C'_s \neq C'_t$. 

Since $p_i$ and $p_j$ are in the same component $C_r$, it must be that 
Kruskal's algorithm added all the edges of a $p_i, p_j$-path $P$ 
before we stopped it. In particular, each edge in $P$ has length at most $d^*$. 
But $p_i \in C'_s$ and $p_j \notin C'_t$, so let $p'$ be the first 
node on $P$ that does not belong to $C'_s$ and let $p$ be the node on $P$
that comes just before $p'$. Then $d(p, p') \leq d^*$ since the edge 
from $p$ to $p'$ was added by Kruskal's algorithm. But $p$ and $p'$ 
belong to different clusters in ${\cal C}'$, so the spacing of ${\cal C}'$ 
is at most $d^*$, as desired. \qed 
\end{pf}