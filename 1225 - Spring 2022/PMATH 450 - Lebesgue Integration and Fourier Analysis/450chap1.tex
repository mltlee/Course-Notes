\section{Motivation}\label{sec:1}
This course is a continuation of PMATH 351. It can be thought of 
as a gateway course to many areas of modern analysis, and has 
many applications such as partial differential equations or even
representation of theory of groups.

Even though this course is called ``Lebesgue Integration and Fourier Analysis'',
we will focus more on the latter, since there is a lot of overlap with 
PMATH 451 in terms of measure theory. First, we will begin by giving a 
hand-wavy derivation of the heat equation. We then try to solve the 
corresponding PDE, which will give us some motivation for studying 
Fourier analysis. 

\subsection{Deriving the Heat Equation}\label{subsec:1.1}
Take a ``nice'' region $D \subseteq \R^3$ with volume, such as a sphere, 
cylinder, or cube. Consider a solid body with shape $D$. At time $t = 0$, 
the body is heated to an initial temperature 
\[ u(x, y, z, t)|_{t=0} = u(x, y, z, 0). \] 
This is our initial condition. Moreover, for all $t > 0$, the temperature on 
the boundary $\partial D$ is specified; that is, we know the values of 
$u(x, y, z, t)$ for all $(x, y, z) \in \partial D$. These are the boundary 
conditions. Our goal is to find $u(x, y, z, t)$ for all $t > 0$ and 
$(x, y, z) \in D$. 

To begin, we will derive (using physics) the PDE governing $u$. The 
solid body with shape given by $D$ is assumed to have constant density
$\rho > 0$, and there is a specific heat constant $c > 0$. Then the 
heat content of $D$ is given by
\[ H(t) = \iiint_D c\rho u(x, y, z, t)\dd V. \] 
Behaving as a physicist would, we toss the derivative into the integral 
without question to obtain 
\begin{equation}\label{eq:1.1}
    H'(t) = \iiint_D c\rho u_t(x, y, z, t)\dd V. 
\end{equation}
Now, Fourier's Law states that heat flows from hotter to colder regions at 
a rate proportional to the temperature gradient 
\[ \nabla u(x, y, z) = (u_x, u_y, u_z). \] 
With our nice region $D$, heat only flows in and out through the surface 
$\partial D$. Then Fourier states that there exists $\kappa > 0$ such that 
$H'(t)$ is equal to $\kappa$ multiplied by the flux of $\nabla u$ through 
$\partial D$. That is, we have 
\[ H'(t) = \iint_{\partial D} \kappa(\nabla u) \cdot {\rm d}\vec{S}, \] 
where ${\rm d}\vec{S}$ is the surface differential $\vec{n} \cdot {\rm d}S$. 
Recall that the divergence of a vector field $\vec{F} = (F_1, F_2, F_3)$ is 
defined by $\divergence(\vec{F}) := (F_1)_x + (F_2)_y + (F_3)_z$, and 
Gauss' Divergence Theorem states that 
\[ \iint_{\partial D} \vec F \cdot {\rm d}\vec S = \iiint_D 
\divergence(\vec{F})\dd V. \] 
In our case, we have $\vec F = \kappa\nabla u = (\kappa u_x, \kappa u_y, 
\kappa u_z)$, and hence 
\[ \divergence(\kappa\nabla u) = \kappa(u_{xx} + u_{yy} + u_{zz}) = \kappa\Delta u, \] 
where $\Delta u = u_{xx} + u_{yy} + u_{zz}$ is the Laplacian of $u$. From 
our above equation, this yields 
\begin{equation}\label{eq:1.2}
    H'(t) = \iiint_D \kappa\Delta u\dd V.
\end{equation}
Combining $\eqref{eq:1.1}$ and $\eqref{eq:1.2}$ and doing some rearranging, 
we end up with 
\[ \iiint_D (c\rho u_t - \kappa\Delta u)\dd V = 0. \] 
This holds for all ``nice'' regions, and implies that 
\[ c\rho u_t - \kappa\Delta u = 0. \] 
Setting $K = \kappa/(c\rho) > 0$, we obtain the heat equation 
\[ u_t = K\Delta u. \] 
We now want to solve this with our given initial and boundary conditions. 
As we would expect, this is very difficult! This is a PDE, and solving an
ODE is already a tall order. 

\subsection{Solving the Heat Equation}
For simplicity, we will instead consider the $1$-dimensional heat equation. 
Let us take a thin rod over the interval $[-\pi, \pi]$. Suppose that this 
rod is laterally insulated so that heat only flows in the $x$-direction. 
In this case, the heat equation is given by 
\[ u_t = K u_{xx}. \] 
Our initial condition is $u(x, 0) = f(x)$ where $f$ is piecewise continuous
or even just Riemann integrable, if we want to be more fancy. As for the 
boundary conditions, this really depends on the physical scenario. We give 
some examples of them below.
\begin{itemize}
    \item We may assert that the temperature is $0$ on the endpoints, so
    $u(-\pi, t) = u(\pi, t) = 0$ for all $t \geq 0$. These are called 
    Dirichlet boundary conditions.
    \item We can also assume that the endpoints are insulated, giving us 
    $u_x(-\pi, t) = u_x(\pi, t) = 0$ for all $t \geq 0$. These are called 
    Neumann boundary conditions.
\end{itemize}
For our purposes, we will consider a mixture of these and say that we have 
periodic boundary conditions. To be specific, we want it so that for all 
$t \geq 0$, we have 
\begin{align*}
    u(-\pi, t) &= u(\pi, t), \\ 
    u_x(-\pi, t) &= u_x(\pi, t).
\end{align*}
Now, we employ separation of variables, which allows us to find candidates for
PDEs. We look for non-zero solutions of the form 
\[ u(x, t) = T(t) X(x), \] 
where $T$ and $X$ are differentiable and not equal to $0$ everywhere. 
Notice that if $u$ solves the PDE $u_t = Ku_{xx}$, then for all 
$t \geq 0$ and $x \in [-\pi, \pi]$, we have 
\[ T'(t)X(x) = KT(t)X''(x). \] 
This implies that 
\[ \frac{T'(t)}{KT(t)} = \frac{X''(x)}{X(x)} \] 
for all $t \geq 0$ such that $T(t) \neq 0$ and $x \in [-\pi, \pi]$ such that 
$X(x) \neq 0$. Now notice that if we keep $t$ fixed and vary $x$, the value 
of $X''(x)/X(x)$ remains unchanged. Similarly, if we keep $x$ fixed and 
vary $t$, the value of $T'(t)/[KT(t)]$ is also unchanged. Therefore, 
there exists some constant $\lambda \in \R$ such that 
\[ \lambda = \frac{T'(t)}{KT(t)} = \frac{X''(x)}{X(x)}. \] 
This yields the equations
\begin{align}
    T'(t) &= -\lambda KT(t), \label{eq:1.3} \\ 
    X''(x) + \lambda X(x) &= 0. \label{eq:1.4}
\end{align}
Now, we put the periodic boundary conditions into play. This gives us 
\begin{align*}
    T(t) X(\pi) &= T(t) X(-\pi), \\ 
    T(t) X'(\pi) &= T(t) X'(-\pi). 
\end{align*}
We will consider equation $\eqref{eq:1.4}$ first. Since we assumed that 
$T$ is not identically $0$, we obtain the eigenvalue 
problem for $X$ given by the following three equations 
\begin{align*}
    X''(x) + \lambda X(x) &= 0, \\
    X(\pi) &= X(-\pi), \\
    X'(\pi) &= X'(-\pi).
\end{align*}
Let us now determine what values of $\lambda$ will work. 

{\sc Case 1.} Suppose that $\lambda > 0$. Then we can write $\lambda = \omega^2$
for some $\omega > 0$. We obtain the equation 
\[ X''(x) + \omega^2 X(x) = 0, \] 
whose only solutions are of the form 
\[ X(x) = C\cos(\omega x) + D\sin(\omega x) \] 
for some constants $C$ and $D$. Using the first boundary condition 
$X(\pi) = X(-\pi)$ gives us 
\[ 2D\sin(\omega\pi) = 0, \] 
so either $D = 0$ or $\omega \in \N$. Similarly, the second boundary 
condition $X'(\pi) = X'(-\pi)$ implies that either $C = 0$ or 
$2C\omega\sin(\omega\pi) = 0$, and the latter scenario means $\omega \in \N$. 
Therefore, we have established that for $n \in \N$, the functions 
\[ X_n(x) = C_n \cos(nx) + D_n \sin(nx) \] 
with constants $C_n$ and $D_n$ are solutions to the eigenvalue problem. 

{\sc Case 2.} Suppose that $\lambda = 0$. Then $X''(x) = 0$, which means that 
\[ X(x) = C + Dx \] 
for some constants $C$ and $D$. It is easily verified that $X(\pi) = X(-\pi)$
gives $D = 0$, and that $X'(\pi) = X'(-\pi)$ gives nothing new. So 
$X_0(x) = C_0$ is a solution to the eigenvalue problem. 

{\sc Case 3.} Suppose that $\lambda < 0$. Then we can write $\lambda = 
-\omega^2$ for some $\omega > 0$. It follows that all solutions to 
$X''(x) - \omega^2 X = 0$ are of the form 
\[ X(x) = C \cosh(\omega x) + D \sinh(\omega x). \] 
Now $X(\pi) = X(-\pi)$ implies that $2D\sinh(\omega\pi) = 0$ and 
$X'(\pi) = X'(-\pi)$ gives us $2C\omega\sinh(\omega\pi) = 0$. These 
together have no nonzero solutions.

Therefore, we have found that $X$ is either of the form $X_0(x) = C_0$
for some constant $C_0$, or 
\[ X_n(x) = C_n\cos(nx) + D_n\sin(nx) \] 
for some $n \in \N$ and constants $C_n$ and $D_n$. Using equation 
$\eqref{eq:1.3}$, we see that $\lambda = 0$ implies that $T(t)$ is constant, 
and $\lambda = n^2 > 0$ implies that 
\[ T(t) = \exp(-Kn^2t). \] 
Then, the solutions for $u$ are $u_0(x, t) = T_0 X_0 = C_0$, and 
\[ u_n(x, t) = \exp(-Kn^2t) (C_n\cos(nx) + D_n\sin(nx)) \]
for all $n \in \N$. Using the Fourier method for PDEs, we notice that 
$u_t = Ku_{xx}$ is linear, so we can take linear combinations such as 
\[ u(x, t) = \sum_{n=0}^N u_n(x, t) \] 
and still obtain a solution. Moreover, by formally interchanging 
sums and derivatives, the boundary conditions are also linear.
However, finite sums can be insufficient for the initial conditions to be 
satisfied too. Thus, we instead consider formal infinite sums to get 
\[ u(x, t) = \sum_{n=0}^\infty u_n(x, t) = C_0 + \sum_{n=1}^\infty 
\exp(-Kn^2t) (C_n\cos(nx) + D_n\sin(nx)). \] 
Assuming that the initial condition holds, this means we can write 
\[ f(x) = u(x, 0) = C_0 + \sum_{n=1}^\infty (C_n\cos(nx) + D_n\sin(nx)). \] 
The above form is known as a {\bf Fourier series}. Now, we recall that 
we can write $\cos(nx) = (e^{inx} + e^{-inx})/2$ and $\sin(nx) = 
(e^{inx} - e^{-inx})/2$, so if we let 
\[ A_n = \begin{cases} 
    C_0, & \text{if } n = 0, \\ 
    (C_n - iD_n)/2, & \text{if } n > 0, \\ 
    (C_{-n} + iD_{-n})/2, & \text{if } n < 0, 
\end{cases} \] 
then we obtain the nice formula 
\[ f(x) = \sum_{n=-\infty}^{\infty} A_n e^{inx}. \] 
This leads us to a few questions.
\begin{enumerate}
    \item Are we justified in interchanging summation and differentiation?
    \item Given some nice function $f$ from $[-\pi, \pi]$ to 
    $\R$ or $\C$, is it possible to express $f$ as the infinite sum 
    $f(x) = \sum_{n=-\infty}^\infty A_n e^{inx}$?
    \begin{enumerate}
        \item If so, in what sense does the sum converge?
        \item How are $f$ and the coefficients $A_n$ related?
    \end{enumerate}
\end{enumerate}

\subsection{Basic Notation}
We will get into answering the above questions later. First, we will make 
some definitions.

\begin{defn}{defn:1.1}
    \begin{itemize}
        \item We define $\T = \{z \in \C : |z| = 1\} = 
        \{e^{i\theta} : \theta \in [-\pi, \pi]\}$ to be the unit circle in $\C$. 
        \item We define $C(\T)$ to be the continuous $\C$-valued functions 
        on $\T$. Notice that we can view $C(\T)$ as the space of
        $2\pi$-periodic functions $\{f \in C[-\pi, \pi] : f(\pi) = f(-\pi)\}$.
        \item We define $R(\T)$ to be the Riemann integrable functions 
        over $\T$. Note that $R(\T) \supseteq C(\T)$. 
    \end{itemize}
\end{defn}

The space $C(\T)$ has many nice norms. 
\begin{itemize}
    \item One such norm is 
    \[ \|f\|_\infty = \sup_{\theta \in [-\pi, \pi]} |f(\theta)|. \] 
    In fact, $(C(\T), \|\cdot\|_\infty)$ is complete, so every 
    Cauchy sequence in $C(\T)$ converges to a limit in $C(\T)$ with respect to 
    $\|\cdot\|_\infty$.
    \item Another norm is given by 
    \[ \|f\|_1 = \frac{1}{2\pi} \int_{-\pi}^\pi |f(\theta)|\dd\theta. \] 
    Note that $C(\T)$ is not complete with respect to $\|\cdot\|_1$; 
    in fact, it is not even complete for $R(\T)$, which hints to us that 
    Riemann integrability may not be enough. 
    \item For functions $f, g \in C(\T)$, one can define an inner product by 
    \[ \langle f, g \rangle = \frac{1}{2\pi} \int_{-\pi}^\pi f(\theta) 
    \overline{g(\theta)}\dd\theta. \] 
    This gives us a norm 
    \[ \|f\|_2 = \langle f, f \rangle^{1/2} = 
    \left( \frac{1}{2\pi} \int_{-\pi}^\pi |f(\theta)|^2\dd\theta \right)^{\!1/2}. \] 
\end{itemize} 
Now, let $f \in C(\T)$, and assume that it makes sense to write it as 
\[ f(\theta) = \sum_{n=-\infty}^\infty A_n e^{in\theta}. \] 
For example, the series could be uniformly convergent. What are the 
coefficients $A_n$?

We claim that 
\[ A_n = \frac{1}{2\pi} \int_{-\pi}^\pi f(\theta) e^{-in\theta}\dd\theta 
=: \hat f(n). \] 
