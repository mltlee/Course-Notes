\section{More Single Machine Models} \label{sec:4}

\subsection{Maximum Lateness with Release Dates} \label{subsec:4.1}
We have already seen in Section~\ref{subsec:2.3} that there is a polynomial 
time algorithm to solve $(1\;\|\;L_{\max})$ instances. This was the 
Earliest Due Date (EDD) rule, which placed the jobs in increasing order of the 
due dates. We also saw that this was a special case of $(1 \mid prec 
\mid h_{\max})$, for which there was also an efficient algorithm, namely 
Lowest Cost Last (LCL). 

But what if we introduce release dates to the $(1\;\|\;L_{\max})$ problem? 
It turns out that this generalization, without preemption, is significantly 
harder than the problem where all jobs are available at time $0$. Moreover, 
the optimal schedule is not necessarily a non-delay schedule. It can be 
advantageous in this case to keep the machine idle before the release of a 
new job. 

\begin{theo}{theo:4.1}
    The problem $(1 \mid r_j \mid L_{\max})$ is strongly $\NP$-hard. 
\end{theo}
\begin{pf}
    This proof is based on the fact that {\sc $3$-Partition} (as described 
    in Example~\ref{exmp:3.14}) reduces to $(1 \mid r_j \mid L_{\max})$. 
    Suppose that we are given integers $a_1, \dots, a_{3t}, b$ such that 
    $\frac{b}{4} < a_j < \frac{b}{2}$ and $\sum_{j=1}^{3t} a_j = t \cdot b$. 
    We construct an instance of $(1 \mid r_j \mid L_{\max})$ with 
    $n = 4t - 1$ as follows: 
    \begin{itemize}
        \item For $j = 1, \dots, t-1$, we set $r_j = jb + (j-1)$, $p_j = 1$, 
        $d_j = jb + j$. 
        \item For $j = t, \dots, 4t-1$, we set $r_j = 0$, $p_j = a_{j-t+1}$, 
        and $d_j = tb + (t-1)$. 
    \end{itemize}
    Notice that a schedule with $L_{\max} \leq 0$ exists if and only if 
    every job $j \in \{1, \dots, t-1\}$ can be processed between 
    $r_j$ and $d_j = r_j + p_j$. This can be done if and only if the remaining 
    jobs can be partitioned over the $t$ intervals of length $b$, which can be 
    done if and only if {\sc $3$-Partition} has a solution. 
\end{pf}

% TODO: Discuss the branch-and-bound approach here 

\subsection{The Number of Tardy Jobs} \label{subsec:4.2}
Recall that $U_j = 0$ if the job is timely and $U_j = 1$ if the job is late. 
The goal of the problem $(1\;\|\;\sum U_j)$ is to minimize the number of 
tardy jobs. Notice that it does not matter how late a job is; the only 
determining factor is if it is late or not. A solution to this problem can 
be represented as a partition of the jobs into sets $S_1$ and $S_2$, where 
$S_1$ is the set of jobs meeting their due dates in Earliest Due Date (EDD)
order, and $S_2$ is the set of late jobs in an arbitrary order (since the 
amount of lateness is irrelevant).  

\begin{lemma}{lemma:4.2}
    Let OPT denote the optimal value for a given instance of $(1\;\|\;\sum U_j)$.
    If the sequence given by the EDD rule has a late job, then $\text{OPT} \geq 1$. 
\end{lemma}
\begin{pf}
    % TODO: See CRS'21 handout. 
\end{pf}

\begin{algo}[Moore-Hodgson]{algo:4.3}
    \begin{enumerate}
        \item Enumerate the jobs in EDD order. 
        \item Set $S_1 \gets \varnothing$ and $t \gets 0$. 
        \item for $j=1$ to $n$ do: 
        \begin{itemize}[\label{}]
            \item Set $S_1 \gets S_1 \cup \{j\}$ and $t \gets t + p_j$. 
            \item if $t > d_j$ then: 
            \begin{itemize}[\label{}]
                \item Find a job $k$ with the largest $p_k$ value in $S_1$. 
                \item Set $S_1 \gets S_1 \setminus \{k\}$ and $t \gets t - p_k$. 
            \end{itemize}
            endif
        \end{itemize}
        endfor
    \end{enumerate}
\end{algo}

The principle of the Moore-Hodgson algorithm is that we schedule the jobs by the EDD 
rule, and when a job gets late, we rescue the situation by throwing out the job with 
the highest processing time. All removed jobs are considered late, and the remaining 
ones are timely. This algorithm runs in $O(n\log n)$ time. 

\begin{exmp}{exmp:4.4}
    Consider the following instance of $(1 \;\|\; \sum U_j)$ with $n = 5$ jobs, 
    where the jobs are already in EDD order.  
    \begin{align*}
        \begin{array}{c|ccccc}
            j   & 1 & 2  & 3  & 4  & 5 \\ \hline 
            p_j & 7 & 8  & 4  & 6  & 6 \\ 
            d_j & 9 & 17 & 18 & 19 & 21
        \end{array}
    \end{align*}
    We can initially schedule jobs $1$ and $2$, which will both be timely. However, 
    once we schedule job $3$, we see that it will be late, since $t = 19 > 18 = d_3$.
    \begin{verbatim}
        |---1---|---2----|-3--|
        0       7        15   19
    \end{verbatim}
    \vspace{-1em}
    Therefore, we toss out job $2$ which has the highest processing time of $p_2 = 8$
    and continue. We can schedule job $4$ just fine, but job $5$ will be late with 
    $t = 23 > 21 = d_5$. 
    \begin{verbatim}
        |---1---|-3--|--4---|--5---|
        0       7    11     17     23
    \end{verbatim}
    \vspace{-1em}
    This time, we toss out job $1$ since it has the highest processing time of $p_1 = 7$. 
    Then we obtain $S_1 = \{3, 4, 5\}$ and $S_2 = \{1, 2\}$, so $\text{OPT} = 2$ for 
    this instance. 
\end{exmp}

The following lemma is the key to proving that the Moore-Hodgson algorithm is 
optimal for $(1\;\|\;\sum U_j)$. We will assume that the jobs are already scheduled 
in EDD. 

\begin{lemma}{lemma:4.5}
    Suppose there is at least one late job in the EDD sequence $1, \dots, n$. 
    Let $k$ be the first late job in the EDD sequence, and let $m$ be the first 
    job rejected by the Moore-Hodgson algorithm. Then there is an optimal 
    schedule which rejects $m$. 
\end{lemma}
\begin{pf}
    % TODO: See handout. 
\end{pf}
 