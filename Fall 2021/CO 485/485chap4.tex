\section{Integer Factorization}

\subsection{Motivation for Integer Factorization}
So far, we have described and implemented efficient algorithms for generating
primes, finding modular inverses, and performing modular exponentiation. 
Therefore, we should now be convinced of the efficiency of the RSA key generation,
encryption, and decryption operations. However, we have not discussed the 
security of the RSA encryption scheme. An adversary may adapt the following 
obvious attack strategy:
\begin{enumerate}
    \item Factor the RSA public modulus $N = pq$. 
    \item Once $p$ and $q$ are known, compute $\phi = (p-1)(q-1)$. 
    \item Recover the secret exponent $d$ by computing the multiplicative inverse
    of $e$ modulo $\phi$. 
    \item Run the decryption algorithm $\Dec(c) = c^d \pmod N$. 
\end{enumerate}
Thus, the security of RSA requires integer factorization to be hard, at least 
in the case where an RSA public key modulus is of the form $N = pq$ for 
two distinct primes $p$ and $q$. 

{\bf Question.} Why must $p$ and $q$ be distinct primes in RSA? We also noted 
that RSA primes $p$ and $q$ should be of the same bit-length; that is, 
$p \approx q$. Why is this the case?

We will describe some integer factorization algorithms and study their efficiency.
This will give us a better sense of the security of RSA, and it might suggest 
some useful criterion in selecting the RSA primes $p$ and $q$. 

\subsection{Problem Definition and a Naive Strategy}
An integer factorization algorithm $\IntFac$ takes a positive integer $N$ as input,
and outputs pairs of primes and positive integers $(p_i, e_i)$ for $m \geq 1$ 
and $i = 1, \dots, m$ such that 
\[ N = \prod_{i=1}^m p_i^{e_i}. \]
A factor finding algorithm $\FindFac$ takes a positive integer $N$ as input. 
When $N$ is composite, $\FindFac$ outputs two nontrivial factors $(n_1, n_2)$ of 
$N$; that is, $1 < n_1, n_2 < N$ such that $N = n_1n_2$. When $N$ is prime, 
$\FindFac$ outputs $(N, 1)$. 

Clearly, an efficient $\IntFac$ yields an efficient $\FindFac$. Conversely, using
$\FindFac$ recursively yields an efficient $\IntFac$. Therefore, we can restrict
our attention to $\FindFac$. For future reference, we note that the binary 
representation of an integer $N$ can be provided as input to factor finding 
or integer factorization algorithms, so we say that the input size is $\log_2 N$. 

The naive primality testing algorithm in Section 3.2 gives us a naive factor 
finding algorithm. Given an integer $N \geq 2$ as input, compute $N \pmod n$
for all integers $2 \leq n \leq \sqrt N$. If the interval $[2, \sqrt N]$ is 
nonempty and there is some $n$ such that $N \equiv 0 \pmod n$, then output 
$(n, N/n)$; otherwise, output $(N, 1)$. Notice that the first case occurs 
if and only if $N$ is composite, and the second case occurs if and only if 
$N$ is prime. For integers of the form $N = pq$ 
with $p \approx q \approx \sqrt N$, this algorithm would need to perform 
about $\sqrt N$ integer divisions before finding a prime factor of $N$. 
The computational complexity of the integer division operation can be 
estimated as $O((\log_2 N)^3)$, which is a polynomial function of the input 
size $\log_2 N$. However, the number of steps $O(\sqrt N)$ is an exponential 
function of the input size, so it would not be feasible to factor commonly 
deployed $2048$-bit RSA moduli using this approach. 

\begin{exercise}
    Suppose an adversary is trying to factor the $2048$-bit modulus $N$ given by 
    \begin{align*}
        & 1657149945513071402293947654868380061019592336471239267077249436980938246913984 \\
        & 6854681124400407952376248085771857669845180280490445594743703975014171144934137 \\
        & 5462712148346840472922092817238029652927492096334047197925289116709232599596512 \\
        & 4538882325103423547556039562732521789245444030511675452311827273389674765661319 \\ 
        & 7555763157125477797269745933804235191987174701777001730108824080893548375470164 \\ 
        & 8289813375824384456296476311382985828848739394326260608105080229109327176724351 \\ 
        & 6845013339095555938796687460497979761890329264690895603572561138043479640686906 \\ 
        & 8286050343393050137892902130389456325438296565890634899457077249
    \end{align*}
    using the naive strategy as described above. The adversary knows that $N$ 
    is a product of two $1024$-bit distinct primes, and the adversary has access
    to a computing resource that can perform $10^{18}$ long divisions per second. 
    Estimate the time the adversary needs to factor $N$.
\end{exercise}

\subsection{Pollard's $p-1$ Algorithm}
Let $N$ be a positive composite integer with a prime factor $p$ such that 
\[ p-1 = \prod_{i=1}^m p_i^{e_i} \] 
where $e_i \geq 1$ is an integer and $p_i$ is prime for all $i = 1, \dots, m$, and 
\[ p_1^{e_1} < p_2^{e_2} < \cdots < p_m^{e_m} \leq B \] 
for some integer $B \in \Z$. Now, let $a \in \Z$. If we are lucky and find that 
$\gcd(a, N) = p$, then we are already done finding a nontrivial factor of $N$. 
Therefore, we assume that $\gcd(a, N) = 1$, and hence $\gcd(a, p) = 1$. 
The above conditions imply that $(p-1) \mid B!$ and it follows from Fermat's 
little theorem that 
\[ a^{B!} \equiv 1 \pmod p, \] 
or equivalently $p \mid (a^{B!} - 1)$, and that $\gcd(a^{B!} - 1, N) > 1$. 
This gives us some hope of finding a nontrivial factor of $N$. One 
initial concern might be that $a^{B!}$ is potentially a very large number 
to the extent that we cannot efficiently handle it. This can be addressed by 
observing that $\gcd(a^{B!}-1, N) = \gcd(a^{B!}-1 \pmod N, N)$. Therefore, 
we can simply work with numbers in $\Z_N$. Moreover, we can find
$a^{B!} \pmod N$ with $B-1$ successive modular exponentiations by computing 
\[ a^{B!} \text{ mod $N$} = ((((a \text{ mod $N$})^2 \text{ mod $N$})^3
\text{ mod $N$})^4 \;\cdots)^B \text{ mod $N$}. \] 
Since all of the exponents are bounded by $B$, each modular exponentiation 
requires at most $\log_2 B$ (modular) multiplications and $\log_2 B$ 
(modular) squarings. Finally, using bit-level computational complexity 
estimates $O((\log_2 N)^2)$ and $O((\log_2 N)^3)$ for modular multiplication 
and GCD finding operations respectively, we estimate 
the number of bit operations for computing $\gcd(a^{B!}-1, N)$ to be 
$O(B\log_2 B (\log_2 N)^2 + (\log_2 N)^3)$. 

In particular, if $B$ is a polynomial function of the input size 
$\log_2 N$, then $\gcd(a^{B!} - 1, N)$ can be computed in polynomial time. 
There is still a possibility that the algorithm may fail to reveal a 
nontrivial factor of $N$. Failure can occur when $B$ is not large enough, or the 
above condition is not satisfied for any prime factor $p$ of $N$; in such 
cases, we have $\gcd(a^{B!} - 1, N) = 1$. Another failure case occurs when 
the above condition is satisfied for all primes $p$ dividing $N$, and 
we have $\gcd(a^{B!} - 1, N) = N$.  

Finally, we present Pollard's $p-1$ algorithm, which takes integers $N$ and 
$B$ as input. It either outputs a nontrivial factor of $N$, or fails to find 
one and exits. Moreover, we will assume that the input $N$ is odd, because 
it is easy to extract the highest power of $2$ dividing $N$. 

\begin{algo}[Pollard's $p-1$ Algorithm]~

    {\bf Input:} A odd positive integer $N \geq 3$ and a positive integer $B$. 
    
    {\bf Output:} A nontrivial factor of $N$, or a failure message. 
    \begin{enumerate}
        \item Set $a \gets 2$ (note that $\gcd(a, N) = 1$). 
        \item {\bf for $i = 2$ to $B$ do:}
        \begin{itemize}
            \item $a \gets a^i \pmod N$. 
        \end{itemize}
        \item Set $n \gets \gcd(a - 1, N)$.
        \item {\bf if $1 < n < N$:}
        \begin{itemize}
            \item Output ``$n$ is a nontrivial factor of $N$'' and exit. 
        \end{itemize}
        {\bf else:}
        \begin{itemize}
            \item Output ``Failed to find a nontrivial factor of $N$'' and exit.
        \end{itemize}
    \end{enumerate}
\end{algo}

\begin{exmp}
    Let $N = 159890872984562826587452273352244481949$ and $B = 256$ be given 
    as input to Pollard's $p-1$ algorithm. For $a = 2$, we find that 
    \[ p = \gcd(a^{B!} - 1, N) = 1460742484010232525119 \] 
    is the $71$-bit nontrivial factor of $N$. We can also verify that 
    $q = N/p = 109458631302081571$ is the second prime factor of $N$. The 
    algorithm worked as expected because $p$ is a prime such that the 
    largest prime power that divides 
    \[ p - 1 = 2 \cdot 163 \cdot 181 \cdot 197 \cdot 199 \cdot 211 \cdot 223 
    \cdot 233 \cdot 239 \cdot 241 \] 
    is bounded above by $B = 256$. Moreover, note that $q$ is a prime such that 
    \[ q - 1 = 2 \cdot 3^2 \cdot 5 \cdot 239 \cdot 84979 \cdot 59882233. \] 
    In particular, it is divisible by at least one prime power greater than 
    $B = 256$.  
\end{exmp}

{\bf Question.} What is the smallest value of $B$ for which Pollard's $p-1$ 
algorithm would successfully output a nontrivial factor of $N$ in Example 4.3?
What is the smallest value of $B$ for which Pollard's $p-1$ 
algorithm would fail to output a nontrivial factor of $N$ in Example 4.3? 

\begin{exercise}
    Is it possible to factor the $2048$-bit RSA modulus $N$ given by 
    \begin{align*}
        & 1657149945513071402293947654868380061019592336471239267077249436980938246913984 \\
        & 6854681124400407952376248085771857669845180280490445594743703975014171144934137 \\
        & 5462712148346840472922092817238029652927492096334047197925289116709232599596512 \\
        & 4538882325103423547556039562732521789245444030511675452311827273389674765661319 \\ 
        & 7555763157125477797269745933804235191987174701777001730108824080893548375470164 \\ 
        & 8289813375824384456296476311382985828848739394326260608105080229109327176724351 \\ 
        & 6845013339095555938796687460497979761890329264690895603572561138043479640686906 \\ 
        & 8286050343393050137892902130389456325438296565890634899457077249
    \end{align*}
    using Pollard's $p-1$ algorithm? If so, what parameter $B$ did you choose? 
    How do you compare the efficiency of Pollard's $p-1$ algorithm to the 
    naive strategy in this case?
\end{exercise}

\subsection{Random Squares Algorithm}
Consider the $160$-bit integer 
\[ N = 922610576830596284853741260709758510725457815261, \] 
which has been carefully generated so that Pollard's $p-1$ algorithm fails to 
find a nontrivial factor of $N$. Suppose that we are lucky and discover an 
integer 
\[ x = 197192464917820788181655076611186929519317134193 \] 
whose square modulo $N$ is a perfect square over the integers; indeed, we can 
write 
\[ x^2 \equiv 123160136679264019196490652341114889 \equiv 
31^2 \cdot 223^2 \cdot 239^2 \cdot 587^2 \cdot 613^2 \cdot 719^2 \cdot 821^2
\pmod N. \] 
Using the difference of squares formula, we can set 
$y = 31 \cdot 223 \cdot 239 \cdot 587 \cdot 613 \cdot 719 \cdot 821$ 
and rewrite the above equality as 
\[ x^2 - y^2 \equiv (x-y)(x+y) \equiv 0 \pmod N. \] 
In other words, we have $N \mid (x-y)(x+y)$, and there is a good chance 
for $\gcd(x-y, N)$ to yield a nontrivial factor of $N$. We can easily check 
that this is the case, and we recover 
\[ p = \gcd(x-y, N) = 815825200225639959767099 \] 
as one of the (prime) factors of $N$. We can also verify that 
$q = N/p = 1130892471298290066461639$ is prime, so we can factor 
\[ N = pq = 815825200225639959767099 \cdot 1130892471298290066461639 \] 
as the product of two prime numbers. 

In factoring $N$ above, we were lucky several times. 
\begin{enumerate}[(1)]
    \item In particular, $x^2 \pmod N$ was a perfect square. We will see later 
    that finding such an $x$ is closely related to discovering numbers 
    $x_i \in \Z$ such that $x_i^2 \pmod N$ is a $B$-smooth integer; that is, 
    all the prime divisors of $x_i^2 \pmod N$ are bounded by $B$. We see that 
    there is a tradeoff here: the probability that a uniformly and randomly 
    chosen number in $\Z_N$ is $B$-smooth increases as $B$ gets larger, 
    but verifying that a number is $B$-smooth and combining $B$-smooth 
    integers to get our desired $x$ becomes more difficult.
    \item After identifying $x$ and $y$ such that $x^2 \equiv y^2 \pmod N$, 
    we saw that $\gcd(x-y, N)$ corresponded to a nontrivial factor of $N$. 
    In our case, $N$ was an RSA modulus, and by the Chinese remainder theorem, 
    there are actually $4$ integers $X$, namely $X \in \{x, N-x, y, N-y\}$, 
    that satisfy $x^2 \equiv y^2 \pmod N$; only two of these yield 
    nontrivial factors of $N$. 
\end{enumerate}

\begin{exercise}
    Suppose that $N = pq$ for distinct primes $p$ and $q$. Moreover, suppose 
    that $x^2 \equiv y^2 \pmod N$ and $\gcd(x-y, N) = p$ as above. Can you 
    determine $\gcd(X-y, N)$ for $X \in \{N-x, y, N-y\}$?
\end{exercise}

Before we describe the random squares algorithm, let's build some 
intuition about it. First, even though factoring is a hard problem in 
general, notice that we can efficiently factor $B$-smooth integers if 
$B$ is relatively small. For an integer $B \geq 2$, define the set 
$\FB(B)$ to be the set of all primes at most $B$. That is, 
\[ \FB(B) := \{p_i : p_i \leq B,\, p_i \text{prime},\, i = 1, \dots, \pi(B)\}. \] 
We call $\FB(B)$ the {\bf factor basis} of $B$. For example, we have 
$\FB(3) = \FB(4) = \{2, 3\}$ with $\pi(3) = \pi(4) = 2$, and 
$\FB(32) = \{2, 3, 5, 7, 11, 13, 17, 19, 23, 29\}$ with $\pi(32) = 10$. 
Now, given an $\ell$-bit integer $Z$, we can conclude whether or not 
$Z$ is $B$-smooth after performing at most $\ell \cdot \pi(B)$ long divisions. 
Moreover, in the case that $Z$ is $B$-smooth, keeping track of the 
(repeated) prime divisors of $Z$ in $\FB(B)$ reveals the factorization of 
$Z$ with respect to $\FB(B)$. 

Clearly, the overall complexity of the random squared factoring algorithm 
will depend heavily on the choice of $B$. We will explicitly analyze this later. 
For now, let's assume that we have fixed some $B$ such that there is a reasonable 
chance for randomly and uniformly chosen integers $\Z_N$ to be $B$-smooth. 
We will describe how to construct an integer $x \in \Z_N$ such that 
$x^2 \equiv y^2 \pmod N$ for some $y$. We first select $x_i \in \Z_N$ 
uniformly at random, until $x_i^2 \pmod N$ is $B$-smooth. Then, we can write 
\[ x_i^2 \text{ (mod $N$)} = \prod_{j=1}^{\pi(B)} p_j^{e_{ij}} \] 
where each $e_{ij} \geq 0$, and we associate each $i$ with a row vector 
\[ e_i = [e_{i1}, e_{i2}, \dots, e_{i\pi(B)}]. \] 
We define a $T \times \pi(B)$ matrix of exponents $M$, where the $i$-th 
row of $M$ is $e_i$. We also define $M_2$ to be the $T \times \pi(B)$ 
boolean matrix obtained from reducing every entry in $M$ modulo $2$. 
Note that for sufficiently large $T$, we will find a subset $I \subseteq 
\{1, \dots, T\}$ of indices such that the rows of $M_2$ corresponding to 
$I$ are linearly dependent modulo $2$; that is, 
\[ \sum_{i \in I} e_i \equiv [0, 0, \dots, 0] \pmod 2, \] 
or equivalently, 
\[ \sum_{i \in I} e_i = 2 \cdot [v_1, v_2, \dots, v_{\pi(B)}] \] 
for some integers $v_1, \dots, v_{\pi(B)} \geq 0$. By the definition of 
$e_i$, we conclude that 
\[ \prod_{i \in I} x_i^2 \equiv 
\left( \prod_{j=1}^{\pi(B)} p_j^{v_j} \right)^{\!2} \pmod N. \] 
In particular, setting $x = \prod_{i \in I} x_i$ and 
$y = \prod_{j=1}^{\pi(B)} p_j^{v_j}$ gives us $x^2 \equiv y^2 \pmod N$. 

\begin{exercise}
    Estimate how large $T$ should be so that the rows of $M_2$ are linearly 
    dependent. 
\end{exercise}

\begin{exmp}
    Let $N = 765481$ be a $20$-bit RSA modulus. We set $B = 32$, so we have 
    $\pi(B) = 10$ and 
    \[ \FB(B) = \{2, 3, 5, 7, 11, 13, 17, 19, 23, 29\}. \] 
    We randomly select values 
    \[ x_1 = 242630,\
    x_2 = 437699,\
    x_3 = 608349,\
    x_4 = 143044,\
    x_5 = 673821,\
    x_6 = 487625,\
    x_7 = 311049, \] 
    and we determine that 
    \begin{align*}
        M &= \begin{pmatrix}
            0&0&1&1&0&0&1&0&0&0\\
            0&0&0&1&1&0&2&1&0&0\\
            1&3&4&0&0&0&0&1&0&0\\
            1&0&0&0&1&0&0&1&1&1\\
            0&3&3&1&0&0&1&0&0&0\\
            3&0&4&0&2&0&0&0&0&0\\
            4&1&0&0&0&0&0&0&0&2
        \end{pmatrix}, &  
        M_2 &= \begin{pmatrix}
            0&0&1&1&0&0&1&0&0&0\\
            0&0&0&1&1&0&0&1&0&0\\
            1&1&0&0&0&0&0&1&0&0\\
            1&0&0&0&1&0&0&1&1&1\\
            0&1&1&1&0&0&1&0&0&0\\
            1&0&0&0&0&0&0&0&0&0\\
            0&1&0&0&0&0&0&0&0&0
        \end{pmatrix}. 
    \end{align*}
    This yields a linearly dependent set of row vectors in $M_2$ with 
    indices $I = \{1, 5, 7\}$. More precisely, we have 
    \[ \sum_{i\in\{1, 5, 7\}} e_i = [4, 4, 4, 2, 0, 0, 2, 0, 0, 2] 
    = 2 \cdot [2, 2, 2, 1, 0, 0, 1, 0, 0, 1]. \] 
    Therefore, we set 
    \begin{align*} 
        x &= x_1x_5x_7 \text{ (mod $N$)} = 654980, \\ 
        y &= 2^2 \cdot 3^2 \cdot 5^2 \cdot 7^1 \cdot 11^0 \cdot 13^0 
        \cdot 17^1 \cdot 19^0 \cdot 23^0 \cdot 29^1 \text{ (mod $N$)} 
        = 43976, 
    \end{align*}
    which satisfy $x^2 \equiv y^2 \pmod N$. Finally, we verify that 
    $p = \gcd(x-y, N) = \gcd(611004, 765481) = 863$ is a prime divisor of $N$. 
    Since $N$ is given to be an RSA modulus, we find that $q = N/p = 887$ is 
    the second prime factor of $N = pq$. 
\end{exmp}

\begin{remark}~
    \begin{enumerate}[(1)]
        \item A linearly dependent subset of rows in $M_2$ can be identified 
        using linear algebra. 
        \item We noted that the $x_i \in \Z_N$ were chosen at random. In the 
        previous example, we chose them such that $x_i \geq \sqrt N$ 
        in order to perform at least one modular reduction when computing 
        $x_i^2 \pmod N$, and to avoid trivial relations. In fact, there 
        are better ways to choose the $x_i \in \Z_N$, which we will discuss later. 
    \end{enumerate}
\end{remark}

Now, we're ready to describe the random squares algorithm and analyze it more 
formally. 

\begin{algo}[Random Squares Algorithm]~

    {\bf Input:} A odd positive integer $N \geq 3$ and a positive integer $B$. 
    
    {\bf Output:} A nontrivial factor of $N$, or a failure message.
    \begin{enumerate}
        \item Set $\FB = \{p_1, p_2, \dots, p_{\pi(B)}\}$ as the factor 
        basis of all primes at most $B$. 
        \item Set an empty matrix $M$, which will eventually be a $T \times 
        \pi(B)$ matrix. 
        \item Set $i \gets 1$ and $T \gets \pi(B) + 1$. 
        \item {\bf Relation generation stage.}
        \begin{itemize}
            \item Select $\sqrt{N} \leq x_i \leq N-1$ uniformly at random. 
            \item {\bf if $x_i^2 \pmod N$ is $B$-smooth:}
            \begin{itemize}[$\circ$]
                \item Write $x_i^2 \pmod N = \prod_{j=1}^{\pi(B)} p_j^{e_{ij}}$ 
                for some $e_{ij} \geq 0$. 
                \item Set $e_i = [e_{i1}, e_{i2}, \dots, e_{i\pi(B)}]$ and append 
                $e_i$ as the $i$-th row of $M$.
                \item $i \gets i+1$.
            \end{itemize}
            \item {\bf if $M$ has reached $T$ rows:}
            \begin{itemize}[$\circ$]
                \item Exit the relation generation stage.
            \end{itemize}
            {\bf else:}
            \begin{itemize}[$\circ$]
                \item Restart the relation generation stage. 
            \end{itemize}
        \end{itemize}
        \item {\bf Linear algebra stage.}
        \begin{itemize}
            \item Compute $M_2 = M \pmod 2$. 
            \item Use linear algebra to find $I \subseteq \{1, \dots, T\}$ 
            so the rows of $M_2$ corresponding to $I$ are linearly 
            dependent. 
            \item Determine integers $v_1, \dots, v_{\pi(B)} \geq 0$ such that 
            $\sum_{i \in I} e_i = 2 \cdot [v_1, v_2, \dots, v_{\pi(B)}]$. 
            \item Set $x = \prod_{i\in I} x_i$ and $y = \prod_{j=1}^{\pi(B)} 
            p_j^{v_j}$. 
        \end{itemize}
        \item {\bf Factor finding stage.}
        \begin{itemize}
            \item Compute $n = \gcd(x-y, N)$. 
            \item {\bf if $1 < n < N$:}
            \begin{itemize}[$\circ$]
                \item Output ``$n$ is a nontrivial factor of $N$''.
            \end{itemize}
            {\bf else:}
            \begin{itemize}[$\circ$]
                \item Output ``Failed to find a nontrivial factor of $N$''. 
            \end{itemize}
        \end{itemize}
    \end{enumerate}
\end{algo}

\newpage 
In order to understand the computational complexity of the random squares 
algorithm, we will analyze the relation generation stage and linear algebra 
stage separately. 

{\bf Relation generation stage.} Let $\Psi(N, B)$ denote the number of 
$B$-smooth integers in $[1, N]$. In our analysis, we will assume that the 
probability of a randomly and uniformly chosen integer in $[1, N]$ being 
$B$-smooth is $\Psi(N, B)/N$. In \cite{CANFIELD19831}, it was discovered that 
\[ \Psi(N,B)/N \approx 1/u^u, \] 
where $u = \ln N/\ln B$. This means that we need to try approximately $u^u$ 
times before $x_i^2 \pmod N$ is $B$-smooth in the relation generation stage. 
As we discussed before, we can check whether an integer is $B$-smooth or 
not after performing at most $\pi(B) (\log_2 N)$ long divisions, or equivalently, 
$\pi(B) (\log_2 N)^3$ bit operations. Therefore, the complexity of generating 
a single relation is about $u^u \pi(B) (\log_2 B)^3$. Since we need to generate 
$T \approx \pi(B)$ relations, the complexity of the relation generation stage 
altogether is 
\[ u^u \pi(B)^2 (\log_2 N)^3. \] 
{\bf Linear algebra stage.} Given a $T \times \pi(B)$ matrix $M$, the boolean 
matrix $M_2 = M \pmod 2$ can be determined by checking the last bit of the 
entries of $M$. Therefore, we estimate the cost of this step to be $\pi(B) 
\cdot T$ bit operations. Then, a linearly dependent subset of rows in $M_2$ 
can be determined by running the Gaussian elimination method in $\Z_2$. 
For each column in $M_2$, we perform at most $T$ binary vector additions 
of dimension $\pi(B)$, or equivalently, $\pi(B) \cdot T$ bit operations. 
Since we have $\pi(B)$ columns to trace and $T \approx \pi(B)$, we estimate 
the bit-level complexity of the linear algebra stage to be 
\[ \pi(B)^2 + \pi(B)^3. \] 
Finally, the factor finding stage requires a GCD computation whose bit-level 
complexity can be estimated as $(\log_2 N)^3$. The overall complexity of the 
random squares algorithm is thus 
\[ u^u \pi(B)^2 (\log_2 N)^3 + \pi(B)^2 + \pi(B)^3 + (\log_2 N)^3 
\leq 4u^u B^3 (\log_2 N)^3. \] 
We focus our attention towards minimizing the function $u^u B^3$. The calculus 
details of optimizing this function are quite tedious; let's take a shortcut 
and try 
\[ \ln B = c\sqrt{\ln N \ln\ln N}. \] 
for some constant $c$. Then $B = e^{c\sqrt{\ln N \ln\ln N}}$, which implies that 
\[ u = \frac{\ln N}{\ln B} = \frac{\ln N}{c\sqrt{\ln N \ln\ln N}} = 
\frac{\sqrt{\ln N}}{c\sqrt{\ln \ln N}}. \] 
This gives 
\[ \ln u = \frac12 \ln\ln N - \left( \ln c + \frac12 \ln\ln\ln N \right) 
= \left( \frac12 + o(1) \right) \ln\ln N, \] 
and hence 
\[ u\ln u = \left( \frac1{2c} + o(1) \right) \sqrt{\ln N \ln\ln N}. \] 
Finally, we see that 
\[ u^u = e^{(\frac1{2c} + o(1)) \sqrt{\ln N \ln\ln N}}. \] 
Therefore, the complexity of the random squares algorithm is bounded by 
$e^{(C + o(1)) \sqrt{\ln N \ln\ln N}}$
for some constant $C$. In fact, using the above estimates more precisely in the 
actual algorithm cost function, we can get the more accurate bound of 
$O(e^{(\max(2c + \frac{1}{2c},\,3c) + o(1)) \sqrt{\ln N \ln\ln N}} (\log_2 N)^3)$,
which is minimized when $c = 1/2$. Thus, we can refine our estimate to 
$O( e^{(2 + o(1)) \sqrt{ \ln N \ln\ln N}} (\log_2 N)^3)$. 
Furthermore, since 
\[ (\log_2 N)^3 = e^{3\ln(\log_2 N)} = e^{o(1) \sqrt{\ln N \ln\ln N}}, \] 
we can write our estimate as $O(e^{(2+o(1))\sqrt{\ln N \ln\ln N}})$. 

\begin{exercise}
    Our complexity analysis of the random squares algorithm implicitly 
    assumes that $\gcd(x-y, N)$ is always a nontrivial factor of $N$, 
    which as we discussed before, does not have to be the case in general. 
    What is the impact of removing this assumption from our complexity analysis? 
\end{exercise}

\subsection{The $L$-function and Some Number Theory Facts}
We estimated the complexity of the random squares algorithm as 
$O(e^{(2+o(1))\sqrt{\ln N \ln\ln N}})$. To ease our notation, we will introduce 
the $L$-function. 

\begin{defn}
    For real numbers $0 \leq \alpha \leq 1$ and $c > 0$, we define the 
    {\bf $L$-function} as 
    \[ L_N[\alpha, c] = e^{(c+o(1))(\ln N)^{\alpha}(\ln\ln N)^{1-\alpha}}. \] 
\end{defn}

In particular, the complexity of the random squares algorithm can be written as 
$L[1/2, 2]$. More generally, 
\begin{itemize}
    \item $L_N[0, c]$ captures complexities polynomial in $\log_2 N$; 
    \item $L_N[1, c]$ captures complexities exponential in $\log_2 N$; and 
    \item for $0 < \alpha < 1$, $L_N[\alpha, c]$ captures complexities 
    subexponential in $\log_2 N$. 
\end{itemize}

We define $\Omega(n)$ as the total number of prime factors (with multiplicity) 
of an integer $n \geq 2$. That is, if $n = \prod_{i=1}^s p_i^{\alpha_i}$, then 
$\Omega(n) = \sum_{i=1}^s \alpha_i$. In our estimate of the complexity of 
checking whether an integer is $B$-smooth, we used the upper bound 
$\Omega(n) \leq \log_2 N$. Note that this upper bound is attained when 
$n = 2^{\alpha}$. For general $n$, we have 
\[ \sum_{x\leq n} \Omega(x) = n\ln\ln n + Cx + o(x), \] 
where $C$ is some constant, yielding the approximation 
\[ \Omega(N) \approx \ln\ln N. \tag{4.1} \] 
Another useful and related formula is 
\[ \sum_{p\leq x} \frac1p = \ln\ln x + Dx + o(1), \] 
where $D$ is a constant.\footnote[1]{In fact, $D$ is known as Merten's constant, and 
$C$ above is $D + \sum_p 1/[p(p-1)]$.} This gives another approximation 
\[ \sum_{p\leq x} \frac1p \approx \ln\ln x. \tag{4.2} \] 
We refer to Chapter XXII in \cite{bams/1183493592} for the proofs of these facts.

\subsection{The Quadratic Sieve Algorithm and its Complexity}
It turns out that the random squares algorithm can be significantly sped up if 

\begin{enumerate}[(1)]
    \item the $x^2 \pmod N$ are carefully chosen rather than at random; 
    \item a sieving method is applied to identify smooth integers among 
    $x^2 \pmod N$; and 
    \item optimized algorithms are used at the linear algebra stage. 
\end{enumerate}

The resulting algorithm is called the quadratic sieve algorithm, whose 
complexity for finding a factor of $N$ can be estimated as 
$O(e^{(1+o(1))\sqrt{\ln N \ln\ln N}})$; see \cite{Pomerance96atale} for the 
full proof. We will briefly explain the details of each step below. 

First of all, rather than choosing $\sqrt N < x < N$ at random and checking 
whether $x^2 \pmod N$ is $B$-smooth as in the random squares algorithm, the 
quadratic sieve algorithm identifies $B$-smooth integers among 
\[ q(w) = (w + \lfloor N \rfloor)^2 - N, \] 
for positive integers $w$ until sufficiently many relations are generated. 
One immediate improvement to notice here is that running into a smooth integer 
is more likely simply because the pool consists of integers roughly the same 
size as $\sqrt N$, rather than $N$. More significantly, the quadratic sieve 
algorithm avoids exhaustively dividing each $q(w)$ by each prime $p \in \FB(B)$; 
instead, it performs division operations only on the integers that are likely 
to be $B$-smooth. We now make two observations. 

\begin{enumerate}[(1)]
    \item Let $p$ be an odd prime. If $N \in \QR_p$, then the solution set 
    of the quadratic equation $q(x) \equiv 0 \pmod p$ is 
    $\{\pm\alpha - \lfloor N \rfloor \pmod p\}$, where $\alpha^2 \equiv N \pmod p$. 
    Note that $\alpha$ can be efficiently determined. In the case that 
    $p \equiv 3 \pmod 4$ and $N \in \QR_p$, then one can set $\alpha = 
    N^{(p+1)/4}$ because we have 
    \[ \alpha^2 \equiv \left( N^{(p+1)/4} \right)^{\!2} \equiv N^{(p-1)/2} N 
    \equiv \left( \frac{N}{p} \right) N \equiv N \pmod p, \] 
    as required. For the more involved case where $p \equiv 1 \pmod 4$, see the 
    \href{https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm}
    {Tonelli-Shanks algorithm}. The case where $p = 2$ is trivial. 
    \item For a prime $p$, let $w \in \Z$ satisfy $q(w) \equiv 0 \pmod p$. 
    Then for all $k \geq 0$, we have $q(w + kp) \equiv 0 \pmod p$. 
\end{enumerate}

We now describe the steps of the quadratic sieve algorithm. 
\begin{enumerate}
    \item Choose $B = e^{c\sqrt{\ln N \ln\ln N}}$ for some $c > 0$ and define 
    $u = \ln\sqrt N / \ln B$ so that $\Phi(\sqrt N, B) \approx 1/u^u$. 
    \item Let $p_i \in \FB(B)$. If $\gcd(p_i, N) > 1$, then output $p_i$ 
    as a nontrivial factor of $N$. Otherwise, and if $N \in \QR_{p_i}$, then 
    find $w_{i,1}, w_{i,2} \in \Z_{p_i}^*$ satisfying $q(w_{i,1}) \equiv 
    q(w_{i,2}) \equiv 0 \pmod{p_i}$. Note that when $p_i = 2$, we have 
    $w_{i,1} = w_{i,2}$. 
    \item Let $X_1 = \max_i q(w_{i,j})$ and choose an integer $X_2 > X_1$ such that 
    $X = X_2 - X_1 \approx \pi(B) u^u$. Note that $X_1 = N^{1/2 + o(1)}$, and that 
    the number of $B$-smooth integers in the interval $[X_1, X_2]$ can be estimated 
    as $X/u^u \approx \pi(B)$. 
    \item Initialize an empty table $T$ indexed by the integers from $X_1$ to $X_2$. 
    \item For each $p_i \in \FB(B)$ with $N \in \QR_{p_i}$ and each $j = 1,2$, 
    iterate through integers $k$ such that $z = q(w_{i,j} + kp_i)$ and $X_1 
    \leq z \leq X_2$. If $T[z]$ is empty, then initialize $T[z] \gets z$. Then, 
    determine the largest $\alpha_i \geq 1$ such that $p^{\alpha_i} \mid z$ 
    and update $T[z] \gets T[z]/p_i^{\alpha_i}$. Associate the pair $[p_i, \alpha_i]$
    to the index $z$. 
    \item At the end of the process, declare each $X_1 \leq z \leq X_2$ with 
    $T[z] = 1$ as a $B$-smooth integer and output the corresponding relation 
    $z = \prod_{i=1}^{\pi(B)} p_i^{\alpha_i}$. By construction, we would expect 
    to find approximately $\pi(B)$ relations, and by (4.2), the total 
    number of iterations can be estimated to be 
    \[ \sum_{p\leq B} \frac{X}{p} \approx X \ln\ln B \approx \pi(B) u^u \ln\ln B. \] 
    Moreover, we expect to perform about $\Omega(\sqrt N) \approx \ln\ln \sqrt N$ 
    by our estimate in (4.1). As a result, a total of approximately $\pi(B)$ 
    relations can be explicitly identified and the complexity of this relation 
    collection stage can be estimated as $\pi(B) u^u \ln\ln B \ln\ln \sqrt N$.
    \item If sufficiently many relations (approximately $\pi(B)$) are collected, 
    then proceed to the linear algebra stage, and then to the factor finding 
    stage, as before. The linear algebra benefits from dealing with sparse 
    and boolean matrices; the complexity can be estimated as $\pi(B)^{2+o(1)}$ 
    rather than $\pi(B)^3$ by using Block-Lanczos or Block-Wiedemann type algorithms. 
\end{enumerate}

Finally, adapting our complexity analysis arguments above for the random squares 
algorithm to the quadratic sieve algorithm, we can deduce the estimate 
\[ Bu^u e^{o(1) \sqrt{\ln N \ln\ln N}} + B^2, \] 
where $B = e^{c\sqrt{\ln N \ln \ln N}}$ and $u^u \approx e^{(\frac{1}{4c} + o(1))
\sqrt{\ln N \ln\ln N}}$, which is optimized when $c = 1/2$ and yields the complexity 
estimate 
\[ L[1/2, 1] = e^{(1+o(1))\sqrt{\ln N \ln\ln N}}. \] 